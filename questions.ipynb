{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "286552a8-cc47-4117-8bdc-229d5f841cde",
   "metadata": {},
   "source": [
    "## What we've done:\n",
    " * clean data\n",
    " * reduce to multi-dimensional vector\n",
    "     - We've decided on bag of words\n",
    "     \n",
    "     \n",
    "## TO DO:\n",
    " * reduce testing data to multi-dimensional vector\n",
    "     - The vectors are only for the words in the training set\n",
    " * classification\n",
    "     - Selene output should be the original phrases before lemmatizing and stop-words\n",
    "     - try a bunch of classifiers\n",
    " * graphing\n",
    "     - graph the outputs of our classifiers\n",
    " * presentation\n",
    "     - create a presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbae0de5-e9c3-4f2a-b778-c657e01638b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk # natural language tool kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "495c1c98-5f24-46ba-a399-ed9023049a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialFrame = pd.read_csv('train.tsv', delimiter = '\\t');\n",
    "initialTestFrame = pd.read_csv('test 2.tsv', delimiter = '\\t');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7e54af4-c210-4760-b1f5-00e6a57b157a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "1       A series of escapades demonstrating the adage ...          2  \n",
       "2                                                A series          2  \n",
       "3                                                       A          2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                          Hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c261959-cac5-4a38-bc1f-4a0d638759d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66287</th>\n",
       "      <td>222348</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66288</th>\n",
       "      <td>222349</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66289</th>\n",
       "      <td>222350</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66290</th>\n",
       "      <td>222351</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66291</th>\n",
       "      <td>222352</td>\n",
       "      <td>11855</td>\n",
       "      <td>predictable scenario</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PhraseId  SentenceId                                             Phrase\n",
       "0        156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1        156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2        156063        8545                                                 An\n",
       "3        156064        8545  intermittently pleasing but mostly routine effort\n",
       "4        156065        8545         intermittently pleasing but mostly routine\n",
       "...         ...         ...                                                ...\n",
       "66287    222348       11855             A long-winded , predictable scenario .\n",
       "66288    222349       11855               A long-winded , predictable scenario\n",
       "66289    222350       11855                                    A long-winded ,\n",
       "66290    222351       11855                                      A long-winded\n",
       "66291    222352       11855                               predictable scenario\n",
       "\n",
       "[66292 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialTestFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa82bd7-f839-45b4-932d-6ee048b71ce6",
   "metadata": {},
   "source": [
    "# Preprocess Data:\n",
    "* Clean the frames of garbage rows\n",
    "* All phrases in lower case\n",
    "* All non-ascii characters removed\n",
    "* All extra spaces removed\n",
    "* All contractions expanded\n",
    "* All punctuation replaced with spaces\n",
    "* All stopwords removed\n",
    "* All words lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d97fc68-19de-44b8-b7a5-85c83d4c426d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleans the initial frame\n",
    "def cleanInitialFrame(df):\n",
    "    cleanList = [] # list to grow\n",
    "    currentSentence = 0 # tracks current sentence\n",
    "    sentenceIDs = {0} \n",
    "    # Iterate row by row\n",
    "    for index, row in df.iterrows():\n",
    "        # If it's the first element, add to list\n",
    "        if (row['SentenceId'] == currentSentence):\n",
    "            continue\n",
    "        else:\n",
    "            cleanList.append([row['PhraseId'], row['SentenceId'], row['Phrase'], row['Sentiment']]);\n",
    "            currentSentence = row['SentenceId']\n",
    "    \n",
    "    # Return a clean frame\n",
    "    return pd.DataFrame(cleanList, columns = ['PhraseId', 'SentenceId', 'Phrase', 'Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a44c705-064c-478c-b95e-264c50a34e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans the initial frame\n",
    "def cleanInitialTestFrame(df):\n",
    "    cleanList = [] # list to grow\n",
    "    currentSentence = 0 # tracks current sentence\n",
    "    sentenceIDs = {0} \n",
    "    # Iterate row by row\n",
    "    for index, row in df.iterrows():\n",
    "        # If it's the first element, add to list\n",
    "        if (row['SentenceId'] == currentSentence):\n",
    "            continue\n",
    "        else:\n",
    "            cleanList.append([row['PhraseId'], row['SentenceId'], row['Phrase']]);\n",
    "            currentSentence = row['SentenceId']\n",
    "    \n",
    "    # Return a clean frame\n",
    "    return pd.DataFrame(cleanList, columns = ['PhraseId', 'SentenceId', 'Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "073371f0-8f01-4627-b764-5c9c57a17841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1        64           2  This quiet , introspective and entertaining in...   \n",
       "2        82           3  Even fans of Ismail Merchant 's work , I suspe...   \n",
       "3       117           4  A positively thrilling combination of ethnogra...   \n",
       "4       157           5  Aggressive self-glorification and a manipulati...   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          4  \n",
       "2          1  \n",
       "3          3  \n",
       "4          1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cleanInitialFrame(initialFrame)\n",
    "#df = initialFrame\n",
    "undf=initialFrame.copy(deep=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47f6abca-9015-47f4-a39c-f8258d939922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156076</td>\n",
       "      <td>8546</td>\n",
       "      <td>Kidman is really the only thing that 's worth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156154</td>\n",
       "      <td>8547</td>\n",
       "      <td>Once you get into its rhythm ... the movie bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156178</td>\n",
       "      <td>8548</td>\n",
       "      <td>I kept wishing I was watching a documentary ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156219</td>\n",
       "      <td>8549</td>\n",
       "      <td>Kinnear does n't aim for our sympathy , but ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156076        8546  Kidman is really the only thing that 's worth ...\n",
       "2    156154        8547  Once you get into its rhythm ... the movie bec...\n",
       "3    156178        8548  I kept wishing I was watching a documentary ab...\n",
       "4    156219        8549  Kinnear does n't aim for our sympathy , but ra..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf = cleanInitialTestFrame(initialTestFrame)\n",
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79094ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerAllPhrases(df):\n",
    "    phrases_list = list(df['Phrase'])\n",
    "\n",
    "    for i in range(len(phrases_list)):\n",
    "        phrases_list[i] = phrases_list[i].lower()\n",
    "    count = 0;\n",
    "    for index, row in df.iterrows():\n",
    "        df.at[index,'Phrase'] = phrases_list[count]\n",
    "        count += 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5413fd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>a series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       a series of escapades demonstrating the adage ...          1  \n",
       "1       a series of escapades demonstrating the adage ...          2  \n",
       "2                                                a series          2  \n",
       "3                                                       a          2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                          hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowerAllPhrases(df)\n",
    "lowerAllPhrases(undf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68043b85-a448-4631-88bf-4282d9f5f5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>an intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156076</td>\n",
       "      <td>8546</td>\n",
       "      <td>kidman is really the only thing that 's worth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156154</td>\n",
       "      <td>8547</td>\n",
       "      <td>once you get into its rhythm ... the movie bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156178</td>\n",
       "      <td>8548</td>\n",
       "      <td>i kept wishing i was watching a documentary ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156219</td>\n",
       "      <td>8549</td>\n",
       "      <td>kinnear does n't aim for our sympathy , but ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3305</th>\n",
       "      <td>222281</td>\n",
       "      <td>11851</td>\n",
       "      <td>not sweet enough to liven up its predictable s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3306</th>\n",
       "      <td>222300</td>\n",
       "      <td>11852</td>\n",
       "      <td>nasty , ugly , pointless and depressing , even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>222314</td>\n",
       "      <td>11853</td>\n",
       "      <td>with tightly organized efficiency , numerous f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>222341</td>\n",
       "      <td>11854</td>\n",
       "      <td>they should have called it gutterball .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>222348</td>\n",
       "      <td>11855</td>\n",
       "      <td>a long-winded , predictable scenario .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3310 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PhraseId  SentenceId                                             Phrase\n",
       "0       156061        8545  an intermittently pleasing but mostly routine ...\n",
       "1       156076        8546  kidman is really the only thing that 's worth ...\n",
       "2       156154        8547  once you get into its rhythm ... the movie bec...\n",
       "3       156178        8548  i kept wishing i was watching a documentary ab...\n",
       "4       156219        8549  kinnear does n't aim for our sympathy , but ra...\n",
       "...        ...         ...                                                ...\n",
       "3305    222281       11851  not sweet enough to liven up its predictable s...\n",
       "3306    222300       11852  nasty , ugly , pointless and depressing , even...\n",
       "3307    222314       11853  with tightly organized efficiency , numerous f...\n",
       "3308    222341       11854            they should have called it gutterball .\n",
       "3309    222348       11855             a long-winded , predictable scenario .\n",
       "\n",
       "[3310 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowerAllPhrases(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15eb27c8-3e41-411a-adb8-adfbfedbf29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-ascii characters using str.replace()\n",
    "def asciiClean(df):\n",
    "    # iterate row by row\n",
    "    for index, row in df.iterrows():\n",
    "        old_str = row['Phrase']\n",
    "        new_str = (old_str.encode('ascii','ignore')).decode()\n",
    "        df.at[index, 'Phrase'] = new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3544c935-4b22-4694-bcfa-1cea5e307ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "asciiClean(df)\n",
    "asciiClean(undf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7fdf94c8-b5f9-443b-87e5-9174e22ecfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "asciiClean(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0d591f9e-4d34-4e4e-ad0a-86b5fa857531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def removeSpaces(df):\n",
    "    for index, row in df.iterrows():\n",
    "        # df['Phrase'] = df['Phrase'].replace([row['Phrase']], re.sub(r'\\s+\\'', \"'\", row['Phrase']))\n",
    "        df.at[index,'Phrase'] = re.sub(r'\\s+\\'', \"'\", row['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a60e9877-ff45-4f2c-9f27-7b7be16d7ea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6304/1934570502.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mremoveSpaces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mremoveSpaces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mundf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6304/3580229757.py\u001b[0m in \u001b[0;36mremoveSpaces\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m# df['Phrase'] = df['Phrase'].replace([row['Phrase']], re.sub(r'\\s+\\'', \"'\", row['Phrase']))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Phrase'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\s+\\''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"'\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Phrase'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_get_values_for_loc\u001b[1;34m(self, series, loc, key)\u001b[0m\n\u001b[0;32m   5182\u001b[0m         \"\"\"\n\u001b[0;32m   5183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5184\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5186\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternal_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         \"\"\"\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "removeSpaces(df)\n",
    "removeSpaces(undf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76807d3d-1f94-44bd-8ddc-27107794c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeSpaces(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f1351-a2cf-47e2-aa2c-6b317654e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "contractions.add('n\\'t', 'not')\n",
    "def expandContractions(df):\n",
    "    for index, row in df.iterrows():\n",
    "        phrase = []\n",
    "        for i in row['Phrase'].split():\n",
    "            phrase.append(contractions.fix(i))\n",
    "        string_version = ' '.join(phrase)\n",
    "        df.at[index, 'Phrase'] = string_version            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8090cd-7829-4229-8fa5-3acebc9ab3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "expandContractions(df)\n",
    "expandContractions(undf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea3aa78-2ba4-41a1-a54e-bbed95550c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "expandContractions(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1953719b-cfcf-4305-a85e-87229e86971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def removePunctuation(df):\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    for index,row in df.iterrows():\n",
    "        phrase = []\n",
    "        for i in row['Phrase'].split():\n",
    "            phrase.append(regex.sub('', i))\n",
    "        string_version = ' '.join(phrase)\n",
    "        df.at[index, 'Phrase'] = string_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efef7239-e180-4929-8dff-fb10b351f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "removePunctuation(df)\n",
    "removePunctuation(undf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d8266f-14b1-489e-baa8-c113fe93103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "removePunctuation(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ec2e70-f456-4161-9f02-4365f68f4e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e666e402-ba3c-4df3-8a7f-1a0ab7cf14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(df):\n",
    "    \n",
    "    phrases_list = list(df['Phrase'])\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    for i in range(len(phrases_list)):\n",
    "        word_tokens = word_tokenize(phrases_list[i])\n",
    "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "        filtered_sentence = []\n",
    "        for w in word_tokens:\n",
    "            if w not in stop_words:\n",
    "                filtered_sentence.append(w)\n",
    "        phrases_list[i] = filtered_sentence\n",
    "    \n",
    "    for i in range(len(phrases_list)):\n",
    "        phrases_list[i] = TreebankWordDetokenizer().detokenize(phrases_list[i])\n",
    "    \n",
    "    count = 0\n",
    "    for index, row in df.iterrows():\n",
    "        # df['Phrase'] = df['Phrase'].replace([row['Phrase']], phrases_list[count])\n",
    "        df.at[index, 'Phrase'] = phrases_list[count]\n",
    "        count += 1\n",
    "\n",
    "    return df      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1abbf5a-b4b1-4ee3-b756-3ebd36ccc3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = removeStopWords(df)\n",
    "undf = removeStopWords(undf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db63992-bd8e-4a73-8bdb-d8d7689e6bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = removeStopWords(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3775faa-eb0c-4adb-8f67-07138761ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef2484b-5731-4c28-9d45-a288220fc236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize     \n",
    "def tag_words(df):\n",
    "    allPhrases = list(df['Phrase'])\n",
    "    for index,row in df.iterrows():\n",
    "        tokenized = word_tokenize(allPhrases[index])\n",
    "        tagged = nltk.pos_tag(tokenized)\n",
    "        df.at[index, 'Phrase'] = tagged\n",
    "\n",
    "def determine_root(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemmatize_phrases(df):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    allPhrases = list(df['Phrase'])\n",
    "    for index,row in df.iterrows():\n",
    "        final_sentence = []\n",
    "        final_tag = list(map(lambda x: (x[0], determine_root(x[1])), allPhrases[index]))\n",
    "        for word, tag in final_tag:\n",
    "            if tag is None:\n",
    "                final_sentence.append(word)\n",
    "            else:\n",
    "                final_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "        final_sentence = ' '.join(final_sentence)\n",
    "        df.at[index, 'Phrase'] = final_sentence             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1e301-5cf8-4136-aa77-ccf0923c17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_words(df)\n",
    "lemmatize_phrases(df)\n",
    "tag_words(undf)\n",
    "lemmatize_phrases(undf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63678295-da9b-43d4-ad4b-417fd07c8bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_words(testdf)\n",
    "lemmatize_phrases(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f855b0ee-0337-4313-8a73-7fdc82849d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f042b-80fc-4ec0-833a-ee7978f4d3aa",
   "metadata": {},
   "source": [
    "# Convert our phrases to a bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfebf1c4-fa4b-4d60-b004-9ee6d148b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectDf = df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4b52ab52-d97d-4ec5-b84c-c568eac7172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testVectDf = testdf.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6cc56db-f1ca-4146-9cc9-8368aed6a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleWord(wordDict, word, index):\n",
    "    # Get the list corresponding to the word\n",
    "    cList = wordDict[word]\n",
    "    cLen = len(cList)\n",
    "    # Get the length of how many zeroes to make\n",
    "    # last space is for current word\n",
    "    zeroLen = index - cLen + 1\n",
    "    zeros = [0] * zeroLen\n",
    "    # Add zeros to the list\n",
    "    cList += zeros\n",
    "    cList[-1] += 1\n",
    "    # Set dictionary to list\n",
    "    wordDict[word] = cList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57b672f0-494f-4cd5-bacb-175d9ed152c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a vector of words\n",
    "def createWordVector(df, testdf):\n",
    "    # Creates a dictionary of words\n",
    "    wordDict = {}\n",
    "    # Create a dictionary of lists for word frequencies in each phrase\n",
    "    for index, row in df.iterrows():\n",
    "        sentence = row['Phrase']\n",
    "        for word in sentence.split():\n",
    "            if word in wordDict:\n",
    "                handleWord(wordDict, word, index)\n",
    "            else:\n",
    "                wordDict[word] = []\n",
    "                handleWord(wordDict, word, index)\n",
    "                \n",
    "    # Create a dictionary of words in the test set (only words in the train set)            \n",
    "    testDict = {}\n",
    "    for index, row in testdf.iterrows():\n",
    "        sentence = row['Phrase']\n",
    "        for word in sentence.split():\n",
    "            if word in wordDict and word in testDict:\n",
    "                handleWord(testDict, word, index)\n",
    "            elif word in wordDict and word not in testDict:\n",
    "                testDict[word] = []\n",
    "                handleWord(testDict, word, index)\n",
    "    \n",
    "    \n",
    "    # Get the phrase count\n",
    "    dfLen = len(df['Phrase'])\n",
    "    testdflen = len(testdf['Phrase'])\n",
    "\n",
    "    # Fill the word frequencies to the length of the dataframe\n",
    "    for key in wordDict:\n",
    "        # Handle train set:\n",
    "        cList = wordDict[key]\n",
    "        cLen = len(cList)\n",
    "        # Get the amount of zeros to fill\n",
    "        zeroLen = dfLen - cLen\n",
    "        zeros = [0] * zeroLen\n",
    "        cList += zeros\n",
    "        wordDict[key] = cList\n",
    "        \n",
    "        # Handle test set:\n",
    "        cLen = 0\n",
    "        cList = []\n",
    "        if key in testDict:\n",
    "            cList = testDict[key]\n",
    "            cLen = len(cList)\n",
    "        # Get the amount of zeros to fill\n",
    "        zeroLen = testdflen - cLen\n",
    "        zeros = [0] * zeroLen\n",
    "        cList += zeros\n",
    "        testDict[key] = cList\n",
    "    \n",
    "    # Add each word to the dataFrame\n",
    "    df2 = pd.DataFrame.from_dict(wordDict)\n",
    "    df3 = pd.DataFrame.from_dict(testDict)\n",
    "    return df2, df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c160acdd-5b04-425e-be07-56b540cbff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "subVectDf, subTestVectDf = createWordVector(vectDf, testVectDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf27a684-54c0-4e0b-a171-8878c3aa150e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>series</th>\n",
       "      <th>of</th>\n",
       "      <th>escapades</th>\n",
       "      <th>demonstrating</th>\n",
       "      <th>the</th>\n",
       "      <th>adage</th>\n",
       "      <th>that</th>\n",
       "      <th>what</th>\n",
       "      <th>is</th>\n",
       "      <th>...</th>\n",
       "      <th>gang-infested</th>\n",
       "      <th>east-vs</th>\n",
       "      <th>servicable</th>\n",
       "      <th>goldie</th>\n",
       "      <th>laughingly</th>\n",
       "      <th>annoyances</th>\n",
       "      <th>herrmann</th>\n",
       "      <th>hearst's</th>\n",
       "      <th>avuncular</th>\n",
       "      <th>chortles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17306 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  series  of  escapades  demonstrating  the  adage  that  what  is  ...  \\\n",
       "0  2       1   4          1              1    3      1     1     1   2  ...   \n",
       "1  0       0   0          0              0    0      0     0     0   1  ...   \n",
       "2  1       0   1          0              0    0      0     0     0   0  ...   \n",
       "3  3       0   2          0              0    1      0     0     0   0  ...   \n",
       "4  1       0   0          0              0    0      0     0     0   0  ...   \n",
       "\n",
       "   gang-infested  east-vs  servicable  goldie  laughingly  annoyances  \\\n",
       "0              0        0           0       0           0           0   \n",
       "1              0        0           0       0           0           0   \n",
       "2              0        0           0       0           0           0   \n",
       "3              0        0           0       0           0           0   \n",
       "4              0        0           0       0           0           0   \n",
       "\n",
       "   herrmann  hearst's  avuncular  chortles  \n",
       "0         0         0          0         0  \n",
       "1         0         0          0         0  \n",
       "2         0         0          0         0  \n",
       "3         0         0          0         0  \n",
       "4         0         0          0         0  \n",
       "\n",
       "[5 rows x 17306 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subVectDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "430a79d3-84bd-48d5-90d5-7e421241830e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>intermittently</th>\n",
       "      <th>pleasing</th>\n",
       "      <th>but</th>\n",
       "      <th>mostly</th>\n",
       "      <th>routine</th>\n",
       "      <th>effort</th>\n",
       "      <th>.</th>\n",
       "      <th>kidman</th>\n",
       "      <th>is</th>\n",
       "      <th>...</th>\n",
       "      <th>underworld</th>\n",
       "      <th>gang-infested</th>\n",
       "      <th>east-vs</th>\n",
       "      <th>servicable</th>\n",
       "      <th>laughingly</th>\n",
       "      <th>annoyances</th>\n",
       "      <th>herrmann</th>\n",
       "      <th>hearst's</th>\n",
       "      <th>avuncular</th>\n",
       "      <th>chortles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17306 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   an  intermittently  pleasing  but  mostly  routine  effort  .  kidman  is  \\\n",
       "0   1               1         1    1       1        1       1  1       0   0   \n",
       "1   0               0         0    0       0        0       0  1       1   1   \n",
       "2   0               0         0    0       0        0       0  1       0   0   \n",
       "3   0               0         0    0       0        0       0  1       0   0   \n",
       "4   0               0         0    1       0        0       0  1       0   0   \n",
       "\n",
       "   ...  underworld  gang-infested  east-vs  servicable  laughingly  \\\n",
       "0  ...           0              0        0           0           0   \n",
       "1  ...           0              0        0           0           0   \n",
       "2  ...           0              0        0           0           0   \n",
       "3  ...           0              0        0           0           0   \n",
       "4  ...           0              0        0           0           0   \n",
       "\n",
       "   annoyances  herrmann  hearst's  avuncular  chortles  \n",
       "0           0         0         0          0         0  \n",
       "1           0         0         0          0         0  \n",
       "2           0         0         0          0         0  \n",
       "3           0         0         0          0         0  \n",
       "4           0         0         0          0         0  \n",
       "\n",
       "[5 rows x 17306 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subTestVectDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "47ba059d-41b6-4728-98a1-aea239b7b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectDf = pd.concat([vectDf, subVectDf], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b2d8a745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>a</th>\n",
       "      <th>series</th>\n",
       "      <th>of</th>\n",
       "      <th>escapades</th>\n",
       "      <th>demonstrating</th>\n",
       "      <th>the</th>\n",
       "      <th>...</th>\n",
       "      <th>gang-infested</th>\n",
       "      <th>east-vs</th>\n",
       "      <th>servicable</th>\n",
       "      <th>goldie</th>\n",
       "      <th>laughingly</th>\n",
       "      <th>annoyances</th>\n",
       "      <th>herrmann</th>\n",
       "      <th>hearst's</th>\n",
       "      <th>avuncular</th>\n",
       "      <th>chortles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>this quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>even fans of ismail merchant's work , i suspec...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>a positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8524</th>\n",
       "      <td>155985</td>\n",
       "      <td>8540</td>\n",
       "      <td>... either you're willing to go with this clau...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8525</th>\n",
       "      <td>155998</td>\n",
       "      <td>8541</td>\n",
       "      <td>despite these annoyances , the capable claybur...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8526</th>\n",
       "      <td>156022</td>\n",
       "      <td>8542</td>\n",
       "      <td>-lrb- tries -rrb- to parody a genre that's alr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>156032</td>\n",
       "      <td>8543</td>\n",
       "      <td>the movie's downfall is to substitute plot for...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>156040</td>\n",
       "      <td>8544</td>\n",
       "      <td>the film is darkly atmospheric , with herrmann...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8529 rows × 17310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PhraseId  SentenceId                                             Phrase  \\\n",
       "0            1           1  a series of escapades demonstrating the adage ...   \n",
       "1           64           2  this quiet , introspective and entertaining in...   \n",
       "2           82           3  even fans of ismail merchant's work , i suspec...   \n",
       "3          117           4  a positively thrilling combination of ethnogra...   \n",
       "4          157           5  aggressive self-glorification and a manipulati...   \n",
       "...        ...         ...                                                ...   \n",
       "8524    155985        8540  ... either you're willing to go with this clau...   \n",
       "8525    155998        8541  despite these annoyances , the capable claybur...   \n",
       "8526    156022        8542  -lrb- tries -rrb- to parody a genre that's alr...   \n",
       "8527    156032        8543  the movie's downfall is to substitute plot for...   \n",
       "8528    156040        8544  the film is darkly atmospheric , with herrmann...   \n",
       "\n",
       "      Sentiment  a  series  of  escapades  demonstrating  the  ...  \\\n",
       "0             1  2       1   4          1              1    3  ...   \n",
       "1             4  0       0   0          0              0    0  ...   \n",
       "2             1  1       0   1          0              0    0  ...   \n",
       "3             3  3       0   2          0              0    1  ...   \n",
       "4             1  1       0   0          0              0    0  ...   \n",
       "...         ... ..     ...  ..        ...            ...  ...  ...   \n",
       "8524          2  0       0   0          0              0    0  ...   \n",
       "8525          2  1       0   2          0              0    3  ...   \n",
       "8526          1  2       0   0          0              0    1  ...   \n",
       "8527          1  0       0   0          0              0    1  ...   \n",
       "8528          2  0       0   0          0              0    2  ...   \n",
       "\n",
       "      gang-infested  east-vs  servicable  goldie  laughingly  annoyances  \\\n",
       "0                 0        0           0       0           0           0   \n",
       "1                 0        0           0       0           0           0   \n",
       "2                 0        0           0       0           0           0   \n",
       "3                 0        0           0       0           0           0   \n",
       "4                 0        0           0       0           0           0   \n",
       "...             ...      ...         ...     ...         ...         ...   \n",
       "8524              0        0           0       0           0           0   \n",
       "8525              0        0           0       0           0           1   \n",
       "8526              0        0           0       0           0           0   \n",
       "8527              0        0           0       0           0           0   \n",
       "8528              0        0           0       0           0           0   \n",
       "\n",
       "      herrmann  hearst's  avuncular  chortles  \n",
       "0            0         0          0         0  \n",
       "1            0         0          0         0  \n",
       "2            0         0          0         0  \n",
       "3            0         0          0         0  \n",
       "4            0         0          0         0  \n",
       "...        ...       ...        ...       ...  \n",
       "8524         0         0          0         0  \n",
       "8525         0         0          0         0  \n",
       "8526         0         0          0         0  \n",
       "8527         0         0          0         0  \n",
       "8528         1         1          1         1  \n",
       "\n",
       "[8529 rows x 17310 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9e0c59ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectDf.iloc[:, 4:17310]\n",
    "y = vectDf.iloc[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e1b114c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X, y, test_size=.35)\n",
    "logrm = LogisticRegression(max_iter = 100000).fit(X2_train, y2_train.ravel())\n",
    "y_pred2 = logrm.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "64ddb681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38203125\n"
     ]
    }
   ],
   "source": [
    "print(logrm.score(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a5a5ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, y, test_size=.3)\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(X1_train,y1_train.ravel())\n",
    "forest_y = regr.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "52c88fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.034619817963344124\n"
     ]
    }
   ],
   "source": [
    "print(regr.score(X1_test, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "34cd38f7-cc1e-4903-a8b6-353c847e0627",
   "metadata": {},
   "outputs": [],
   "source": [
    "testVectDf = pd.concat([testVectDf, subTestVectDf], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556c1808-1675-4044-92e4-d4c167f1eca9",
   "metadata": {},
   "source": [
    "# Selene Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8af0d713-b74e-44ab-90d1-5780bfe2843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class Selene(object):\n",
    "    \n",
    "    def __init__(self, df, testdf):\n",
    "        \n",
    "        self.df = df\n",
    "        self.testdf = testdf\n",
    "        self.wordsDict = {}\n",
    "        self.wordSentOcc = {}\n",
    "        self.wordSentVal = {}\n",
    "        self.results = pd.DataFrame\n",
    "    \n",
    "    def train(self, printer = False):\n",
    "        # Tokenizes phrases and finds frequency & sentiment\n",
    "        self.setUniqueWords()\n",
    "        self.setFrequencies()\n",
    "        self.findSentFrequency()\n",
    "        if printer:\n",
    "            counter = 0;\n",
    "            print(\"Words = [Frequency, 0 Freq, 1 Freq, 2 Freq, 3 Freq, 4 Freq]\")\n",
    "            for key, value in self.wordsDict.items():\n",
    "                print(\"Word #\", counter, \":\", key, \"-\", value)\n",
    "                counter += 1\n",
    "    \n",
    "    def test(self, weight = 0.4, minFreq = 3):\n",
    "        self.findWordSentVal()\n",
    "        results = self.getSentiment(weight, minFreq)\n",
    "        return results\n",
    "    \n",
    "    # Finds unique words in the list of phrases and puts into list\n",
    "    def setUniqueWords(self):\n",
    "        \n",
    "        phrases = list(self.df['Phrase'])\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            sentence = row['Phrase']\n",
    "            for w in word_tokenize(sentence): # word_tokens:\n",
    "                if w.isalpha():\n",
    "                    self.wordsDict[w] = [0,0,0,0,0,0]\n",
    "                    \n",
    "    def setFrequencies(self):\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            sentence = row['Phrase']\n",
    "            for word in sentence.split():\n",
    "                if word in self.wordsDict:\n",
    "                    self.wordsDict[word][0] += 1           \n",
    "    \n",
    "    # Finds frequencies of the sentiment per word\n",
    "    def findSentFrequency(self):\n",
    "                    \n",
    "        for index, row in df.iterrows():\n",
    "            sentiment = int(row['Sentiment'])\n",
    "            for word in row['Phrase'].split():\n",
    "                if word in self.wordsDict:\n",
    "                    try:\n",
    "                        self.wordsDict[word][sentiment + 1] += 1\n",
    "                    except:\n",
    "                        print(sentiment + 1)\n",
    "            \n",
    "    # Finds probabilities for a word's sentiment\n",
    "    def findProbabilities(self, key):\n",
    "        \n",
    "        prob0 = self.wordsDict[key][0 + 1] / self.wordsDict[key][0]\n",
    "        prob1 = self.wordsDict[key][1 + 1] / self.wordsDict[key][0]\n",
    "        prob2 = self.wordsDict[key][2 + 1] / self.wordsDict[key][0]\n",
    "        prob3 = self.wordsDict[key][3 + 1] / self.wordsDict[key][0]\n",
    "        prob4 = self.wordsDict[key][4 + 1] / self.wordsDict[key][0]\n",
    "        return prob0, prob1, prob2, prob3, prob4\n",
    "    \n",
    "    # Finds the average sentiment of a word\n",
    "    def findWordSentVal(self):\n",
    "        \n",
    "        for key, value in self.wordsDict.items():\n",
    "            sentVal = (((value[0 + 1] * 0) + (value[1 + 1] * 1) + (value[2 + 1] * 2)\n",
    "                    + (value[3 + 1] * 3) + (value[4 + 1] * 4)) / self.wordsDict[key][0])\n",
    "            prob0, prob1, prob2, prob3, prob4 = self.findProbabilities(key)\n",
    "            self.wordSentVal[key] = {'Avg Value': sentVal,'P0': prob0,\n",
    "                                     'P1': prob1, 'P2': prob2, \n",
    "                                     'P3': prob3, 'P4': prob4}\n",
    "            \n",
    "\n",
    "    \n",
    "    # Gets probability weights\n",
    "    def getWeight(self, word, weightPercent):\n",
    "        \n",
    "        mystery = random.random()\n",
    "        dip0 = self.wordSentVal[word]['P0']\n",
    "        dip1 = dip0 + self.wordSentVal[word]['P1']\n",
    "        dip2 = dip1 + self.wordSentVal[word]['P2']\n",
    "        dip3 = dip2 + self.wordSentVal[word]['P3']\n",
    "        dip4 = dip3 + self.wordSentVal[word]['P4']\n",
    "            \n",
    "        if (mystery >= 0 and mystery < dip0):\n",
    "            return -2 * weightPercent\n",
    "        elif (mystery >= dip0 and mystery < dip1):\n",
    "            return -1 * weightPercent\n",
    "        elif (mystery >= dip1 and mystery < dip2):\n",
    "            return 0\n",
    "        elif (mystery >= dip2 and mystery < dip3):\n",
    "            return 1 * weightPercent\n",
    "        elif (mystery >= dip3 and mystery <= dip4):\n",
    "            return 2 * weightPercent\n",
    "    \n",
    "    def mostOccurances(self, word):\n",
    "        \n",
    "        buffer = -1\n",
    "        maximum = []\n",
    "        for i in range(1,6):\n",
    "            if self.wordsDict[word][i] > buffer:\n",
    "                buffer = self.wordsDict[word][i]\n",
    "                maximum.clear()\n",
    "                maximum.append(i - 1)\n",
    "            if self.wordsDict[word][i] >= buffer:\n",
    "                maximum.append(i - 1)\n",
    "        \n",
    "        if len(maximum) == 1:\n",
    "            return maximum[0]\n",
    "        else:\n",
    "            return sum(maximum)/len(maximum)\n",
    "        \n",
    "    # Gets the sentiment of a phrase\n",
    "    def getSentiment(self, weightPercent = .4, minimumOccurances = 4):\n",
    "        \n",
    "        Sentiments = []\n",
    "        for index, row in self.testdf.iterrows():\n",
    "            \n",
    "            phraseVal = 0\n",
    "            counter = 0\n",
    "            \n",
    "            for word in row['Phrase'].split():\n",
    "                \n",
    "                if word in self.wordSentVal and self.wordsDict[word][0] >= minimumOccurances:\n",
    "                    weight = self.getWeight(word, weightPercent)\n",
    "                    phraseVal += self.wordSentVal[word]['Avg Value'] + weight\n",
    "                    counter += 1\n",
    "                    #if index == 3:\n",
    "                     #   print(word, self.wordsDict[word][0], self.wordSentVal[word]['Avg Value'], weight)\n",
    "                        \n",
    "                elif word in self.wordSentVal and self.wordsDict[word][0] < minimumOccurances:\n",
    "                    weight = self.getWeight(word, weightPercent)\n",
    "                    most = self.mostOccurances(word)\n",
    "                    phraseVal += random.uniform(most - .5, most + .5) + weight\n",
    "                    counter += 1\n",
    "                    #if index == 3:\n",
    "                     #   print(word, self.wordsDict[word][0], most, weight)\n",
    "                        \n",
    "                # Neutral sentiment for unknown word\n",
    "                #else:\n",
    "                 #   phraseVal += random.randint(0, 4)\n",
    "                  #  counter += 1\n",
    "                    \n",
    "            if counter > 0:\n",
    "                #len(row['Phrase'].split())\n",
    "                sentVal = phraseVal/counter\n",
    "                if (sentVal < 0):\n",
    "                    sentVal = 0\n",
    "                elif (sentVal > 4):\n",
    "                    sentVal = 4\n",
    "                Sentiments.append(sentVal)\n",
    "            else:\n",
    "                Sentiments.append(0)\n",
    "            #print(row['Phrase'], Sentiments[index])\n",
    "                        \n",
    "        # testdf['Sentiment'] = Sentiments\n",
    "        #for value in Sentiments:\n",
    "         #   print(value)\n",
    "        # print(Sentiments[1], Sentiments[5])\n",
    "        print(len(list(testdf['Phrase'])), len(Sentiments))\n",
    "        data = {'Phrase': list(testdf['Phrase']), 'Sentiment Predicted': Sentiments}\n",
    "        self.results = pd.DataFrame(data)\n",
    "        return self.results\n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "95c188e5-b06e-45c4-b591-aab0a1df1e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selene = Selene(df, testdf)\n",
    "selene2 = Selene(undf, testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "99e95b78-9ba8-4580-8b00-ccdf93064872",
   "metadata": {},
   "outputs": [],
   "source": [
    "selene.train()\n",
    "selene2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eb2786de-3131-429f-97dd-24b740c23f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3310 3310\n",
      "3310 3310\n"
     ]
    }
   ],
   "source": [
    "sent = selene.test(weight = .75, minFreq = 3)\n",
    "sent2 = selene2.test(weight = .75, minFreq = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "da2f4818-5f83-460d-9b5e-641ec3ebd43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent.to_csv('Predicted_Results.csv', index=False)\n",
    "sent2.to_csv('Predicted_Results2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
