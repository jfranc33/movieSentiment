{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "286552a8-cc47-4117-8bdc-229d5f841cde",
   "metadata": {},
   "source": [
    "## What we've done:\n",
    " * clean data\n",
    " * reduce to multi-dimensional vector\n",
    "     - We've decided on bag of words\n",
    "     \n",
    "     \n",
    "## TO DO:\n",
    " * reduce testing data to multi-dimensional vector\n",
    "     - The vectors are only for the words in the training set\n",
    " * classification\n",
    "     - Selene output should be the original phrases before lemmatizing and stop-words\n",
    "     - try a bunch of classifiers\n",
    " * graphing\n",
    "     - graph the outputs of our classifiers\n",
    " * presentation\n",
    "     - create a presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bbae0de5-e9c3-4f2a-b778-c657e01638b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk # natural language tool kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "495c1c98-5f24-46ba-a399-ed9023049a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialFrame = pd.read_csv('train.tsv', delimiter = '\\t');\n",
    "initialTestFrame = pd.read_csv('test 2.tsv', delimiter = '\\t');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7e54af4-c210-4760-b1f5-00e6a57b157a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "1       A series of escapades demonstrating the adage ...          2  \n",
       "2                                                A series          2  \n",
       "3                                                       A          2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                          Hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c261959-cac5-4a38-bc1f-4a0d638759d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66287</th>\n",
       "      <td>222348</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66288</th>\n",
       "      <td>222349</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66289</th>\n",
       "      <td>222350</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66290</th>\n",
       "      <td>222351</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66291</th>\n",
       "      <td>222352</td>\n",
       "      <td>11855</td>\n",
       "      <td>predictable scenario</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PhraseId  SentenceId                                             Phrase\n",
       "0        156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1        156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2        156063        8545                                                 An\n",
       "3        156064        8545  intermittently pleasing but mostly routine effort\n",
       "4        156065        8545         intermittently pleasing but mostly routine\n",
       "...         ...         ...                                                ...\n",
       "66287    222348       11855             A long-winded , predictable scenario .\n",
       "66288    222349       11855               A long-winded , predictable scenario\n",
       "66289    222350       11855                                    A long-winded ,\n",
       "66290    222351       11855                                      A long-winded\n",
       "66291    222352       11855                               predictable scenario\n",
       "\n",
       "[66292 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialTestFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa82bd7-f839-45b4-932d-6ee048b71ce6",
   "metadata": {},
   "source": [
    "# Preprocess Data:\n",
    "* Clean the frames of garbage rows\n",
    "* All phrases in lower case\n",
    "* All non-ascii characters removed\n",
    "* All extra spaces removed\n",
    "* All contractions expanded\n",
    "* All punctuation replaced with spaces\n",
    "* All stopwords removed\n",
    "* All words lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d97fc68-19de-44b8-b7a5-85c83d4c426d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleans the initial frame\n",
    "def cleanInitialFrame(df):\n",
    "    cleanList = [] # list to grow\n",
    "    currentSentence = 0 # tracks current sentence\n",
    "    sentenceIDs = {0} \n",
    "    # Iterate row by row\n",
    "    for index, row in df.iterrows():\n",
    "        # If it's the first element, add to list\n",
    "        if (row['SentenceId'] == currentSentence):\n",
    "            continue\n",
    "        else:\n",
    "            cleanList.append([row['PhraseId'], row['SentenceId'], row['Phrase'], row['Sentiment']]);\n",
    "            currentSentence = row['SentenceId']\n",
    "    \n",
    "    # Return a clean frame\n",
    "    return pd.DataFrame(cleanList, columns = ['PhraseId', 'SentenceId', 'Phrase', 'Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a44c705-064c-478c-b95e-264c50a34e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans the initial frame\n",
    "def cleanInitialTestFrame(df):\n",
    "    cleanList = [] # list to grow\n",
    "    currentSentence = 0 # tracks current sentence\n",
    "    sentenceIDs = {0} \n",
    "    # Iterate row by row\n",
    "    for index, row in df.iterrows():\n",
    "        # If it's the first element, add to list\n",
    "        if (row['SentenceId'] == currentSentence):\n",
    "            continue\n",
    "        else:\n",
    "            cleanList.append([row['PhraseId'], row['SentenceId'], row['Phrase']]);\n",
    "            currentSentence = row['SentenceId']\n",
    "    \n",
    "    # Return a clean frame\n",
    "    return pd.DataFrame(cleanList, columns = ['PhraseId', 'SentenceId', 'Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "073371f0-8f01-4627-b764-5c9c57a17841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cleanInitialFrame(initialFrame)\n",
    "df = initialFrame\n",
    "undf=initialFrame.copy(deep=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "47f6abca-9015-47f4-a39c-f8258d939922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156076</td>\n",
       "      <td>8546</td>\n",
       "      <td>Kidman is really the only thing that 's worth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156154</td>\n",
       "      <td>8547</td>\n",
       "      <td>Once you get into its rhythm ... the movie bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156178</td>\n",
       "      <td>8548</td>\n",
       "      <td>I kept wishing I was watching a documentary ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156219</td>\n",
       "      <td>8549</td>\n",
       "      <td>Kinnear does n't aim for our sympathy , but ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156076        8546  Kidman is really the only thing that 's worth ...\n",
       "2    156154        8547  Once you get into its rhythm ... the movie bec...\n",
       "3    156178        8548  I kept wishing I was watching a documentary ab...\n",
       "4    156219        8549  Kinnear does n't aim for our sympathy , but ra..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf = cleanInitialTestFrame(initialTestFrame)\n",
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79094ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerAllPhrases(df):\n",
    "    phrases_list = list(df['Phrase'])\n",
    "\n",
    "    for i in range(len(phrases_list)):\n",
    "        phrases_list[i] = phrases_list[i].lower()\n",
    "    count = 0;\n",
    "    for index, row in df.iterrows():\n",
    "        df.at[index,'Phrase'] = phrases_list[count]\n",
    "        count += 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5413fd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>a series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       a series of escapades demonstrating the adage ...          1  \n",
       "1       a series of escapades demonstrating the adage ...          2  \n",
       "2                                                a series          2  \n",
       "3                                                       a          2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                          hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowerAllPhrases(df)\n",
    "lowerAllPhrases(undf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68043b85-a448-4631-88bf-4282d9f5f5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>an intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156076</td>\n",
       "      <td>8546</td>\n",
       "      <td>kidman is really the only thing that 's worth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156154</td>\n",
       "      <td>8547</td>\n",
       "      <td>once you get into its rhythm ... the movie bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156178</td>\n",
       "      <td>8548</td>\n",
       "      <td>i kept wishing i was watching a documentary ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156219</td>\n",
       "      <td>8549</td>\n",
       "      <td>kinnear does n't aim for our sympathy , but ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3305</th>\n",
       "      <td>222281</td>\n",
       "      <td>11851</td>\n",
       "      <td>not sweet enough to liven up its predictable s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3306</th>\n",
       "      <td>222300</td>\n",
       "      <td>11852</td>\n",
       "      <td>nasty , ugly , pointless and depressing , even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>222314</td>\n",
       "      <td>11853</td>\n",
       "      <td>with tightly organized efficiency , numerous f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>222341</td>\n",
       "      <td>11854</td>\n",
       "      <td>they should have called it gutterball .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>222348</td>\n",
       "      <td>11855</td>\n",
       "      <td>a long-winded , predictable scenario .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3310 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PhraseId  SentenceId                                             Phrase\n",
       "0       156061        8545  an intermittently pleasing but mostly routine ...\n",
       "1       156076        8546  kidman is really the only thing that 's worth ...\n",
       "2       156154        8547  once you get into its rhythm ... the movie bec...\n",
       "3       156178        8548  i kept wishing i was watching a documentary ab...\n",
       "4       156219        8549  kinnear does n't aim for our sympathy , but ra...\n",
       "...        ...         ...                                                ...\n",
       "3305    222281       11851  not sweet enough to liven up its predictable s...\n",
       "3306    222300       11852  nasty , ugly , pointless and depressing , even...\n",
       "3307    222314       11853  with tightly organized efficiency , numerous f...\n",
       "3308    222341       11854            they should have called it gutterball .\n",
       "3309    222348       11855             a long-winded , predictable scenario .\n",
       "\n",
       "[3310 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowerAllPhrases(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15eb27c8-3e41-411a-adb8-adfbfedbf29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-ascii characters using str.replace()\n",
    "def asciiClean(df):\n",
    "    # iterate row by row\n",
    "    for index, row in df.iterrows():\n",
    "        old_str = row['Phrase']\n",
    "        new_str = (old_str.encode('ascii','ignore')).decode()\n",
    "        df.at[index, 'Phrase'] = new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3544c935-4b22-4694-bcfa-1cea5e307ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "asciiClean(df)\n",
    "asciiClean(undf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7fdf94c8-b5f9-443b-87e5-9174e22ecfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "asciiClean(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d591f9e-4d34-4e4e-ad0a-86b5fa857531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def removeSpaces(df):\n",
    "    for index, row in df.iterrows():\n",
    "        # df['Phrase'] = df['Phrase'].replace([row['Phrase']], re.sub(r'\\s+\\'', \"'\", row['Phrase']))\n",
    "        df.at[index,'Phrase'] = re.sub(r'\\s+\\'', \"'\", row['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a60e9877-ff45-4f2c-9f27-7b7be16d7ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeSpaces(df)\n",
    "removeSpaces(undf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "76807d3d-1f94-44bd-8ddc-27107794c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeSpaces(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e51f1351-a2cf-47e2-aa2c-6b317654e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "contractions.add('n\\'t', 'not')\n",
    "def expandContractions(df):\n",
    "    for index, row in df.iterrows():\n",
    "        phrase = []\n",
    "        for i in row['Phrase'].split():\n",
    "            phrase.append(contractions.fix(i))\n",
    "        string_version = ' '.join(phrase)\n",
    "        df.at[index, 'Phrase'] = string_version            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "df8090cd-7829-4229-8fa5-3acebc9ab3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "expandContractions(df)\n",
    "expandContractions(undf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cea3aa78-2ba4-41a1-a54e-bbed95550c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "expandContractions(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1953719b-cfcf-4305-a85e-87229e86971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def removePunctuation(df):\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    for index,row in df.iterrows():\n",
    "        phrase = []\n",
    "        for i in row['Phrase'].split():\n",
    "            phrase.append(regex.sub('', i))\n",
    "        string_version = ' '.join(phrase)\n",
    "        df.at[index, 'Phrase'] = string_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "efef7239-e180-4929-8dff-fb10b351f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "removePunctuation(df)\n",
    "removePunctuation(undf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "25d8266f-14b1-489e-baa8-c113fe93103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "removePunctuation(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c7ec2e70-f456-4161-9f02-4365f68f4e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\andyv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\andyv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e666e402-ba3c-4df3-8a7f-1a0ab7cf14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(df):\n",
    "    \n",
    "    phrases_list = list(df['Phrase'])\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    for i in range(len(phrases_list)):\n",
    "        word_tokens = word_tokenize(phrases_list[i])\n",
    "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "        filtered_sentence = []\n",
    "        for w in word_tokens:\n",
    "            if w not in stop_words:\n",
    "                filtered_sentence.append(w)\n",
    "        phrases_list[i] = filtered_sentence\n",
    "    \n",
    "    for i in range(len(phrases_list)):\n",
    "        phrases_list[i] = TreebankWordDetokenizer().detokenize(phrases_list[i])\n",
    "    \n",
    "    count = 0\n",
    "    for index, row in df.iterrows():\n",
    "        # df['Phrase'] = df['Phrase'].replace([row['Phrase']], phrases_list[count])\n",
    "        df.at[index, 'Phrase'] = phrases_list[count]\n",
    "        count += 1\n",
    "\n",
    "    return df      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f1abbf5a-b4b1-4ee3-b756-3ebd36ccc3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = removeStopWords(df)\n",
    "undf = removeStopWords(undf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7db63992-bd8e-4a73-8bdb-d8d7689e6bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = removeStopWords(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b3775faa-eb0c-4adb-8f67-07138761ee81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\andyv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\andyv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\andyv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8ef2484b-5731-4c28-9d45-a288220fc236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize     \n",
    "def tag_words(df):\n",
    "    allPhrases = list(df['Phrase'])\n",
    "    for index,row in df.iterrows():\n",
    "        tokenized = word_tokenize(allPhrases[index])\n",
    "        tagged = nltk.pos_tag(tokenized)\n",
    "        df.at[index, 'Phrase'] = tagged\n",
    "\n",
    "def determine_root(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemmatize_phrases(df):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    allPhrases = list(df['Phrase'])\n",
    "    for index,row in df.iterrows():\n",
    "        final_sentence = []\n",
    "        final_tag = list(map(lambda x: (x[0], determine_root(x[1])), allPhrases[index]))\n",
    "        for word, tag in final_tag:\n",
    "            if tag is None:\n",
    "                final_sentence.append(word)\n",
    "            else:\n",
    "                final_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "        final_sentence = ' '.join(final_sentence)\n",
    "        df.at[index, 'Phrase'] = final_sentence             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dda1e301-5cf8-4136-aa77-ccf0923c17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_words(df)\n",
    "lemmatize_phrases(df)\n",
    "tag_words(undf)\n",
    "lemmatize_phrases(undf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "63678295-da9b-43d4-ad4b-417fd07c8bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_words(testdf)\n",
    "lemmatize_phrases(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f855b0ee-0337-4313-8a73-7fdc82849d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>series escapades demonstrating adage good goos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>series escapades demonstrating adage good goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>escapade demonstrate adage good goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>escapade demonstrate adage good goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>escapade</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrate adage good goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  series escapades demonstrating adage good goos...   \n",
       "1         2           1    series escapades demonstrating adage good goose   \n",
       "2         3           1                                             series   \n",
       "3         4           1                                                      \n",
       "4         5           1                                             series   \n",
       "5         6           1              escapade demonstrate adage good goose   \n",
       "6         7           1                                                      \n",
       "7         8           1              escapade demonstrate adage good goose   \n",
       "8         9           1                                           escapade   \n",
       "9        10           1                       demonstrate adage good goose   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  \n",
       "5          2  \n",
       "6          2  \n",
       "7          2  \n",
       "8          2  \n",
       "9          2  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f042b-80fc-4ec0-833a-ee7978f4d3aa",
   "metadata": {},
   "source": [
    "# Convert our phrases to a bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cfebf1c4-fa4b-4d60-b004-9ee6d148b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectDf = df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4b52ab52-d97d-4ec5-b84c-c568eac7172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testVectDf = testdf.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a6cc56db-f1ca-4146-9cc9-8368aed6a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleWord(wordDict, word, index):\n",
    "    # Get the list corresponding to the word\n",
    "    cList = wordDict[word]\n",
    "    cLen = len(cList)\n",
    "    # Get the length of how many zeroes to make\n",
    "    # last space is for current word\n",
    "    zeroLen = index - cLen + 1\n",
    "    zeros = [0] * zeroLen\n",
    "    # Add zeros to the list\n",
    "    cList += zeros\n",
    "    cList[-1] += 1\n",
    "    # Set dictionary to list\n",
    "    wordDict[word] = cList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "57b672f0-494f-4cd5-bacb-175d9ed152c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a vector of words\n",
    "def createWordVector(df, testdf):\n",
    "    # Creates a dictionary of words\n",
    "    wordDict = {}\n",
    "    # Create a dictionary of lists for word frequencies in each phrase\n",
    "    for index, row in df.iterrows():\n",
    "        sentence = row['Phrase']\n",
    "        for word in sentence.split():\n",
    "            if word in wordDict:\n",
    "                handleWord(wordDict, word, index)\n",
    "            else:\n",
    "                wordDict[word] = []\n",
    "                handleWord(wordDict, word, index)\n",
    "                \n",
    "    # Create a dictionary of words in the test set (only words in the train set)            \n",
    "    testDict = {}\n",
    "    for index, row in testdf.iterrows():\n",
    "        sentence = row['Phrase']\n",
    "        for word in sentence.split():\n",
    "            if word in wordDict and word in testDict:\n",
    "                handleWord(testDict, word, index)\n",
    "            elif word in wordDict and word not in testDict:\n",
    "                testDict[word] = []\n",
    "                handleWord(testDict, word, index)\n",
    "    \n",
    "    \n",
    "    # Get the phrase count\n",
    "    dfLen = len(df['Phrase'])\n",
    "    testdflen = len(testdf['Phrase'])\n",
    "\n",
    "    # Fill the word frequencies to the length of the dataframe\n",
    "    for key in wordDict:\n",
    "        # Handle train set:\n",
    "        cList = wordDict[key]\n",
    "        cLen = len(cList)\n",
    "        # Get the amount of zeros to fill\n",
    "        zeroLen = dfLen - cLen\n",
    "        zeros = [0] * zeroLen\n",
    "        cList += zeros\n",
    "        wordDict[key] = cList\n",
    "        \n",
    "        # Handle test set:\n",
    "        cLen = 0\n",
    "        cList = []\n",
    "        if key in testDict:\n",
    "            cList = testDict[key]\n",
    "            cLen = len(cList)\n",
    "        # Get the amount of zeros to fill\n",
    "        zeroLen = testdflen - cLen\n",
    "        zeros = [0] * zeroLen\n",
    "        cList += zeros\n",
    "        testDict[key] = cList\n",
    "    \n",
    "    # Add each word to the dataFrame\n",
    "    df2 = pd.DataFrame.from_dict(wordDict)\n",
    "    df3 = pd.DataFrame.from_dict(testDict)\n",
    "    return df2, df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c160acdd-5b04-425e-be07-56b540cbff40",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\andyv\\movieSentiment\\movieAnalysis.ipynb Cell 40'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/andyv/movieSentiment/movieAnalysis.ipynb#ch0000039?line=0'>1</a>\u001b[0m subVectDf, subTestVectDf \u001b[39m=\u001b[39m createWordVector(vectDf, testVectDf)\n",
      "\u001b[1;32mc:\\Users\\andyv\\movieSentiment\\movieAnalysis.ipynb Cell 39'\u001b[0m in \u001b[0;36mcreateWordVector\u001b[1;34m(df, testdf)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andyv/movieSentiment/movieAnalysis.ipynb#ch0000038?line=51'>52</a>\u001b[0m     testDict[key] \u001b[39m=\u001b[39m cList\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andyv/movieSentiment/movieAnalysis.ipynb#ch0000038?line=53'>54</a>\u001b[0m \u001b[39m# Add each word to the dataFrame\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/andyv/movieSentiment/movieAnalysis.ipynb#ch0000038?line=54'>55</a>\u001b[0m df2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame\u001b[39m.\u001b[39;49mfrom_dict(wordDict)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andyv/movieSentiment/movieAnalysis.ipynb#ch0000038?line=55'>56</a>\u001b[0m df3 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(testDict)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andyv/movieSentiment/movieAnalysis.ipynb#ch0000038?line=56'>57</a>\u001b[0m \u001b[39mreturn\u001b[39;00m df2, df3\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:1677\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[1;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/frame.py?line=1673'>1674</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39monly recognize index or columns for orient\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/frame.py?line=1675'>1676</a>\u001b[0m \u001b[39mif\u001b[39;00m orient \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/frame.py?line=1676'>1677</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(data, index\u001b[39m=\u001b[39;49mindex, columns\u001b[39m=\u001b[39;49mcolumns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m   <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/frame.py?line=1677'>1678</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/frame.py?line=1678'>1679</a>\u001b[0m     realdata \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/frame.py?line=629'>630</a>\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/frame.py?line=630'>631</a>\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/frame.py?line=631'>632</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/frame.py?line=633'>634</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/frame.py?line=634'>635</a>\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/frame.py?line=635'>636</a>\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/frame.py?line=636'>637</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/frame.py?line=637'>638</a>\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=493'>494</a>\u001b[0m     arrays \u001b[39m=\u001b[39m [\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=494'>495</a>\u001b[0m         x\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=495'>496</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x\u001b[39m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=496'>497</a>\u001b[0m         \u001b[39melse\u001b[39;00m x\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=497'>498</a>\u001b[0m         \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=498'>499</a>\u001b[0m     ]\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=499'>500</a>\u001b[0m     \u001b[39m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=501'>502</a>\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:125\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=121'>122</a>\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=123'>124</a>\u001b[0m     \u001b[39m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=124'>125</a>\u001b[0m     arrays \u001b[39m=\u001b[39m _homogenize(arrays, index, dtype)\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=125'>126</a>\u001b[0m     \u001b[39m# _homogenize ensures\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=126'>127</a>\u001b[0m     \u001b[39m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=127'>128</a>\u001b[0m     \u001b[39m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=130'>131</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=131'>132</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=132'>133</a>\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:625\u001b[0m, in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=621'>622</a>\u001b[0m             val \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(val)\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=622'>623</a>\u001b[0m         val \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mfast_multiget(val, oindex\u001b[39m.\u001b[39m_values, default\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mnan)\n\u001b[1;32m--> <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=624'>625</a>\u001b[0m     val \u001b[39m=\u001b[39m sanitize_array(\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=625'>626</a>\u001b[0m         val, index, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, raise_cast_failure\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=626'>627</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=627'>628</a>\u001b[0m     com\u001b[39m.\u001b[39mrequire_length_match(val, index)\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/internals/construction.py?line=629'>630</a>\u001b[0m homogenized\u001b[39m.\u001b[39mappend(val)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\construction.py:593\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/construction.py?line=590'>591</a>\u001b[0m     subarr \u001b[39m=\u001b[39m _try_cast(data, dtype, copy, raise_cast_failure)\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/construction.py?line=591'>592</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/construction.py?line=592'>593</a>\u001b[0m     subarr \u001b[39m=\u001b[39m maybe_convert_platform(data)\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/construction.py?line=593'>594</a>\u001b[0m     \u001b[39mif\u001b[39;00m subarr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/construction.py?line=594'>595</a>\u001b[0m         subarr \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, subarr)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:122\u001b[0m, in \u001b[0;36mmaybe_convert_platform\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/dtypes/cast.py?line=118'>119</a>\u001b[0m arr: ArrayLike\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/dtypes/cast.py?line=120'>121</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(values, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, \u001b[39mrange\u001b[39m)):\n\u001b[1;32m--> <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/dtypes/cast.py?line=121'>122</a>\u001b[0m     arr \u001b[39m=\u001b[39m construct_1d_object_array_from_listlike(values)\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/dtypes/cast.py?line=122'>123</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/dtypes/cast.py?line=123'>124</a>\u001b[0m     \u001b[39m# The caller is responsible for ensuring that we have np.ndarray\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/dtypes/cast.py?line=124'>125</a>\u001b[0m     \u001b[39m#  or ExtensionArray here.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/dtypes/cast.py?line=125'>126</a>\u001b[0m     arr \u001b[39m=\u001b[39m values\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1980\u001b[0m, in \u001b[0;36mconstruct_1d_object_array_from_listlike\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/dtypes/cast.py?line=1960'>1961</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/dtypes/cast.py?line=1961'>1962</a>\u001b[0m \u001b[39mTransform any list-like object in a 1-dimensional numpy array of object\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/dtypes/cast.py?line=1962'>1963</a>\u001b[0m \u001b[39mdtype.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/dtypes/cast.py?line=1975'>1976</a>\u001b[0m \u001b[39m1-dimensional numpy array of dtype object\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/dtypes/cast.py?line=1976'>1977</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/dtypes/cast.py?line=1977'>1978</a>\u001b[0m \u001b[39m# numpy will try to interpret nested lists as further dimensions, hence\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/dtypes/cast.py?line=1978'>1979</a>\u001b[0m \u001b[39m# making a 1D array that contains list-likes is a bit tricky:\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/dtypes/cast.py?line=1979'>1980</a>\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(\u001b[39mlen\u001b[39;49m(values), dtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mobject\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/dtypes/cast.py?line=1980'>1981</a>\u001b[0m result[:] \u001b[39m=\u001b[39m values\n\u001b[0;32m   <a href='file:///c%3A/Users/andyv/anaconda3/lib/site-packages/pandas/core/dtypes/cast.py?line=1981'>1982</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "subVectDf, subTestVectDf = createWordVector(vectDf, testVectDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf27a684-54c0-4e0b-a171-8878c3aa150e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>escapades</th>\n",
       "      <th>demonstrating</th>\n",
       "      <th>adage</th>\n",
       "      <th>good</th>\n",
       "      <th>goose</th>\n",
       "      <th>also</th>\n",
       "      <th>gander</th>\n",
       "      <th>occasionally</th>\n",
       "      <th>amuse</th>\n",
       "      <th>...</th>\n",
       "      <th>smallbudget</th>\n",
       "      <th>underworld</th>\n",
       "      <th>ganginfested</th>\n",
       "      <th>eastvs</th>\n",
       "      <th>servicable</th>\n",
       "      <th>goldie</th>\n",
       "      <th>laughingly</th>\n",
       "      <th>herrmann</th>\n",
       "      <th>avuncular</th>\n",
       "      <th>chortle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   series  escapades  demonstrating  adage  good  goose  also  gander  \\\n",
       "0       1          1              1      1     2      1     1       1   \n",
       "1       0          0              0      0     0      0     0       0   \n",
       "2       0          0              0      0     0      0     0       0   \n",
       "3       0          0              0      0     0      0     0       0   \n",
       "4       0          0              0      0     0      0     0       0   \n",
       "\n",
       "   occasionally  amuse  ...  smallbudget  underworld  ganginfested  eastvs  \\\n",
       "0             1      1  ...            0           0             0       0   \n",
       "1             0      0  ...            0           0             0       0   \n",
       "2             0      0  ...            0           0             0       0   \n",
       "3             0      0  ...            0           0             0       0   \n",
       "4             0      0  ...            0           0             0       0   \n",
       "\n",
       "   servicable  goldie  laughingly  herrmann  avuncular  chortle  \n",
       "0           0       0           0         0          0        0  \n",
       "1           0       0           0         0          0        0  \n",
       "2           0       0           0         0          0        0  \n",
       "3           0       0           0         0          0        0  \n",
       "4           0       0           0         0          0        0  \n",
       "\n",
       "[5 rows x 14112 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subVectDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a79d3-84bd-48d5-90d5-7e421241830e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intermittently</th>\n",
       "      <th>please</th>\n",
       "      <th>mostly</th>\n",
       "      <th>routine</th>\n",
       "      <th>effort</th>\n",
       "      <th>kidman</th>\n",
       "      <th>really</th>\n",
       "      <th>thing</th>\n",
       "      <th>worth</th>\n",
       "      <th>watch</th>\n",
       "      <th>...</th>\n",
       "      <th>indefinitely</th>\n",
       "      <th>smallbudget</th>\n",
       "      <th>underworld</th>\n",
       "      <th>ganginfested</th>\n",
       "      <th>eastvs</th>\n",
       "      <th>servicable</th>\n",
       "      <th>laughingly</th>\n",
       "      <th>herrmann</th>\n",
       "      <th>avuncular</th>\n",
       "      <th>chortle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   intermittently  please  mostly  routine  effort  kidman  really  thing  \\\n",
       "0               1       1       1        1       1       0       0      0   \n",
       "1               0       0       0        0       0       1       1      1   \n",
       "2               0       0       0        0       0       0       0      0   \n",
       "3               0       0       0        0       0       0       0      0   \n",
       "4               0       0       0        0       0       0       0      0   \n",
       "\n",
       "   worth  watch  ...  indefinitely  smallbudget  underworld  ganginfested  \\\n",
       "0      0      0  ...             0            0           0             0   \n",
       "1      1      1  ...             0            0           0             0   \n",
       "2      0      0  ...             0            0           0             0   \n",
       "3      0      1  ...             0            0           0             0   \n",
       "4      0      0  ...             0            0           0             0   \n",
       "\n",
       "   eastvs  servicable  laughingly  herrmann  avuncular  chortle  \n",
       "0       0           0           0         0          0        0  \n",
       "1       0           0           0         0          0        0  \n",
       "2       0           0           0         0          0        0  \n",
       "3       0           0           0         0          0        0  \n",
       "4       0           0           0         0          0        0  \n",
       "\n",
       "[5 rows x 14112 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subTestVectDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba059d-41b6-4728-98a1-aea239b7b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectDf = pd.concat([vectDf, subVectDf], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd38f7-cc1e-4903-a8b6-353c847e0627",
   "metadata": {},
   "outputs": [],
   "source": [
    "testVectDf = pd.concat([testVectDf, subTestVectDf], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556c1808-1675-4044-92e4-d4c167f1eca9",
   "metadata": {},
   "source": [
    "# Selene Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8af0d713-b74e-44ab-90d1-5780bfe2843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class Selene(object):\n",
    "    \n",
    "    def __init__(self, df, testdf):\n",
    "        \n",
    "        self.df = df\n",
    "        self.testdf = testdf\n",
    "        self.wordsDict = {}\n",
    "        self.wordSentOcc = {}\n",
    "        self.wordSentVal = {}\n",
    "        self.results = pd.DataFrame\n",
    "    \n",
    "    def train(self, printer = False):\n",
    "        # Tokenizes phrases and finds frequency & sentiment\n",
    "        self.setUniqueWords()\n",
    "        self.setFrequencies()\n",
    "        self.findSentFrequency()\n",
    "        if printer:\n",
    "            counter = 0;\n",
    "            print(\"Words = [Frequency, 0 Freq, 1 Freq, 2 Freq, 3 Freq, 4 Freq]\")\n",
    "            for key, value in self.wordsDict.items():\n",
    "                print(\"Word #\", counter, \":\", key, \"-\", value)\n",
    "                counter += 1\n",
    "    \n",
    "    def test(self, weight = 0.4, minFreq = 3):\n",
    "        self.findWordSentVal()\n",
    "        results = self.getSentiment(weight, minFreq)\n",
    "        return results\n",
    "    \n",
    "    # Finds unique words in the list of phrases and puts into list\n",
    "    def setUniqueWords(self):\n",
    "        \n",
    "        phrases = list(self.df['Phrase'])\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            sentence = row['Phrase']\n",
    "            for w in word_tokenize(sentence): # word_tokens:\n",
    "                if w.isalpha():\n",
    "                    self.wordsDict[w] = [0,0,0,0,0,0]\n",
    "                    \n",
    "    def setFrequencies(self):\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            sentence = row['Phrase']\n",
    "            for word in sentence.split():\n",
    "                if word in self.wordsDict:\n",
    "                    self.wordsDict[word][0] += 1           \n",
    "    \n",
    "    # Finds frequencies of the sentiment per word\n",
    "    def findSentFrequency(self):\n",
    "                    \n",
    "        for index, row in df.iterrows():\n",
    "            sentiment = int(row['Sentiment'])\n",
    "            for word in row['Phrase'].split():\n",
    "                if word in self.wordsDict:\n",
    "                    try:\n",
    "                        self.wordsDict[word][sentiment + 1] += 1\n",
    "                    except:\n",
    "                        print(sentiment + 1)\n",
    "            \n",
    "    # Finds probabilities for a word's sentiment\n",
    "    def findProbabilities(self, key):\n",
    "        \n",
    "        prob0 = self.wordsDict[key][0 + 1] / self.wordsDict[key][0]\n",
    "        prob1 = self.wordsDict[key][1 + 1] / self.wordsDict[key][0]\n",
    "        prob2 = self.wordsDict[key][2 + 1] / self.wordsDict[key][0]\n",
    "        prob3 = self.wordsDict[key][3 + 1] / self.wordsDict[key][0]\n",
    "        prob4 = self.wordsDict[key][4 + 1] / self.wordsDict[key][0]\n",
    "        return prob0, prob1, prob2, prob3, prob4\n",
    "    \n",
    "    # Finds the average sentiment of a word\n",
    "    def findWordSentVal(self):\n",
    "        \n",
    "        for key, value in self.wordsDict.items():\n",
    "            sentVal = (((value[0 + 1] * 0) + (value[1 + 1] * 1) + (value[2 + 1] * 2)\n",
    "                    + (value[3 + 1] * 3) + (value[4 + 1] * 4)) / self.wordsDict[key][0])\n",
    "            prob0, prob1, prob2, prob3, prob4 = self.findProbabilities(key)\n",
    "            self.wordSentVal[key] = {'Avg Value': sentVal,'P0': prob0,\n",
    "                                     'P1': prob1, 'P2': prob2, \n",
    "                                     'P3': prob3, 'P4': prob4}\n",
    "            \n",
    "\n",
    "    \n",
    "    # Gets probability weights\n",
    "    def getWeight(self, word, weightPercent):\n",
    "        \n",
    "        mystery = random.random()\n",
    "        dip0 = self.wordSentVal[word]['P0']\n",
    "        dip1 = dip0 + self.wordSentVal[word]['P1']\n",
    "        dip2 = dip1 + self.wordSentVal[word]['P2']\n",
    "        dip3 = dip2 + self.wordSentVal[word]['P3']\n",
    "        dip4 = dip3 + self.wordSentVal[word]['P4']\n",
    "            \n",
    "        if (mystery >= 0 and mystery < dip0):\n",
    "            return -2 * weightPercent\n",
    "        elif (mystery >= dip0 and mystery < dip1):\n",
    "            return -1 * weightPercent\n",
    "        elif (mystery >= dip1 and mystery < dip2):\n",
    "            return 0\n",
    "        elif (mystery >= dip2 and mystery < dip3):\n",
    "            return 1 * weightPercent\n",
    "        elif (mystery >= dip3 and mystery <= dip4):\n",
    "            return 2 * weightPercent\n",
    "    \n",
    "    def mostOccurances(self, word):\n",
    "        \n",
    "        buffer = -1\n",
    "        maximum = []\n",
    "        for i in range(1,6):\n",
    "            if self.wordsDict[word][i] > buffer:\n",
    "                buffer = self.wordsDict[word][i]\n",
    "                maximum.clear()\n",
    "                maximum.append(i - 1)\n",
    "            if self.wordsDict[word][i] >= buffer:\n",
    "                maximum.append(i - 1)\n",
    "        \n",
    "        if len(maximum) == 1:\n",
    "            return maximum[0]\n",
    "        else:\n",
    "            return sum(maximum)/len(maximum)\n",
    "        \n",
    "    # Gets the sentiment of a phrase\n",
    "    def getSentiment(self, weightPercent = .4, minimumOccurances = 4):\n",
    "        \n",
    "        Sentiments = []\n",
    "        for index, row in self.testdf.iterrows():\n",
    "            \n",
    "            phraseVal = 0\n",
    "            counter = 0\n",
    "            \n",
    "            for word in row['Phrase'].split():\n",
    "                \n",
    "                if word in self.wordSentVal and self.wordsDict[word][0] >= minimumOccurances:\n",
    "                    weight = self.getWeight(word, weightPercent)\n",
    "                    phraseVal += self.wordSentVal[word]['Avg Value'] + weight\n",
    "                    counter += 1\n",
    "                    #if index == 3:\n",
    "                     #   print(word, self.wordsDict[word][0], self.wordSentVal[word]['Avg Value'], weight)\n",
    "                        \n",
    "                elif word in self.wordSentVal and self.wordsDict[word][0] < minimumOccurances:\n",
    "                    weight = self.getWeight(word, weightPercent)\n",
    "                    most = self.mostOccurances(word)\n",
    "                    phraseVal += random.uniform(most - .5, most + .5) + weight\n",
    "                    counter += 1\n",
    "                    #if index == 3:\n",
    "                     #   print(word, self.wordsDict[word][0], most, weight)\n",
    "                        \n",
    "                # Neutral sentiment for unknown word\n",
    "                #else:\n",
    "                 #   phraseVal += random.randint(0, 4)\n",
    "                  #  counter += 1\n",
    "                    \n",
    "            if counter > 0:\n",
    "                #len(row['Phrase'].split())\n",
    "                sentVal = phraseVal/counter\n",
    "                if (sentVal < 0):\n",
    "                    sentVal = 0\n",
    "                elif (sentVal > 4):\n",
    "                    sentVal = 4\n",
    "                Sentiments.append(sentVal)\n",
    "            else:\n",
    "                Sentiments.append(0)\n",
    "            #print(row['Phrase'], Sentiments[index])\n",
    "                        \n",
    "        # testdf['Sentiment'] = Sentiments\n",
    "        #for value in Sentiments:\n",
    "         #   print(value)\n",
    "        # print(Sentiments[1], Sentiments[5])\n",
    "        print(len(list(testdf['Phrase'])), len(Sentiments))\n",
    "        data = {'Phrase': list(testdf['Phrase']), 'Sentiment Predicted': Sentiments}\n",
    "        self.results = pd.DataFrame(data)\n",
    "        return self.results\n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "95c188e5-b06e-45c4-b591-aab0a1df1e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selene = Selene(df, testdf)\n",
    "selene2 = Selene(undf, testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "99e95b78-9ba8-4580-8b00-ccdf93064872",
   "metadata": {},
   "outputs": [],
   "source": [
    "selene.train()\n",
    "selene2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eb2786de-3131-429f-97dd-24b740c23f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3310 3310\n",
      "3310 3310\n"
     ]
    }
   ],
   "source": [
    "sent = selene.test(weight = .75, minFreq = 3)\n",
    "sent2 = selene2.test(weight = .75, minFreq = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "da2f4818-5f83-460d-9b5e-641ec3ebd43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent.to_csv('Predicted_Results.csv', index=False)\n",
    "sent2.to_csv('Predicted_Results2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
