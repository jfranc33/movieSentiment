{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "286552a8-cc47-4117-8bdc-229d5f841cde",
   "metadata": {},
   "source": [
    "## What we've done:\n",
    " * clean data\n",
    " * reduce to multi-dimensional vector\n",
    "     - We've decided on bag of words\n",
    "     \n",
    "     \n",
    "## TO DO:\n",
    " * reduce testing data to multi-dimensional vector\n",
    "     - The vectors are only for the words in the training set\n",
    " * classification\n",
    "     - Selene output should be the original phrases before lemmatizing and stop-words\n",
    "     - try a bunch of classifiers\n",
    " * graphing\n",
    "     - graph the outputs of our classifiers\n",
    " * presentation\n",
    "     - create a presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbae0de5-e9c3-4f2a-b778-c657e01638b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk # natural language tool kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "495c1c98-5f24-46ba-a399-ed9023049a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialFrame = pd.read_csv('train.tsv', delimiter = '\\t');\n",
    "initialTestFrame = pd.read_csv('test 2.tsv', delimiter = '\\t');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e54af4-c210-4760-b1f5-00e6a57b157a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "1       A series of escapades demonstrating the adage ...          2  \n",
       "2                                                A series          2  \n",
       "3                                                       A          2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                          Hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c261959-cac5-4a38-bc1f-4a0d638759d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66287</th>\n",
       "      <td>222348</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66288</th>\n",
       "      <td>222349</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66289</th>\n",
       "      <td>222350</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66290</th>\n",
       "      <td>222351</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66291</th>\n",
       "      <td>222352</td>\n",
       "      <td>11855</td>\n",
       "      <td>predictable scenario</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PhraseId  SentenceId                                             Phrase\n",
       "0        156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1        156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2        156063        8545                                                 An\n",
       "3        156064        8545  intermittently pleasing but mostly routine effort\n",
       "4        156065        8545         intermittently pleasing but mostly routine\n",
       "...         ...         ...                                                ...\n",
       "66287    222348       11855             A long-winded , predictable scenario .\n",
       "66288    222349       11855               A long-winded , predictable scenario\n",
       "66289    222350       11855                                    A long-winded ,\n",
       "66290    222351       11855                                      A long-winded\n",
       "66291    222352       11855                               predictable scenario\n",
       "\n",
       "[66292 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialTestFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa82bd7-f839-45b4-932d-6ee048b71ce6",
   "metadata": {},
   "source": [
    "# Preprocess Data:\n",
    "* Clean the frames of garbage rows\n",
    "* All phrases in lower case\n",
    "* All non-ascii characters removed\n",
    "* All extra spaces removed\n",
    "* All contractions expanded\n",
    "* All punctuation replaced with spaces\n",
    "* All stopwords removed\n",
    "* All words lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d97fc68-19de-44b8-b7a5-85c83d4c426d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleans the initial frame\n",
    "def cleanInitialFrame(df):\n",
    "    cleanList = [] # list to grow\n",
    "    currentSentence = 0 # tracks current sentence\n",
    "    sentenceIDs = {0} \n",
    "    # Iterate row by row\n",
    "    for index, row in df.iterrows():\n",
    "        # If it's the first element, add to list\n",
    "        if (row['SentenceId'] == currentSentence):\n",
    "            continue\n",
    "        else:\n",
    "            cleanList.append([row['PhraseId'], row['SentenceId'], row['Phrase'], row['Sentiment']]);\n",
    "            currentSentence = row['SentenceId']\n",
    "    \n",
    "    # Return a clean frame\n",
    "    return pd.DataFrame(cleanList, columns = ['PhraseId', 'SentenceId', 'Phrase', 'Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a44c705-064c-478c-b95e-264c50a34e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans the initial frame\n",
    "def cleanInitialTestFrame(df):\n",
    "    cleanList = [] # list to grow\n",
    "    currentSentence = 0 # tracks current sentence\n",
    "    sentenceIDs = {0} \n",
    "    # Iterate row by row\n",
    "    for index, row in df.iterrows():\n",
    "        # If it's the first element, add to list\n",
    "        if (row['SentenceId'] == currentSentence):\n",
    "            continue\n",
    "        else:\n",
    "            cleanList.append([row['PhraseId'], row['SentenceId'], row['Phrase']]);\n",
    "            currentSentence = row['SentenceId']\n",
    "    \n",
    "    # Return a clean frame\n",
    "    return pd.DataFrame(cleanList, columns = ['PhraseId', 'SentenceId', 'Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "073371f0-8f01-4627-b764-5c9c57a17841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1        64           2  This quiet , introspective and entertaining in...   \n",
       "2        82           3  Even fans of Ismail Merchant 's work , I suspe...   \n",
       "3       117           4  A positively thrilling combination of ethnogra...   \n",
       "4       157           5  Aggressive self-glorification and a manipulati...   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          4  \n",
       "2          1  \n",
       "3          3  \n",
       "4          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cleanInitialFrame(initialFrame)\n",
    "#df = initialFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47f6abca-9015-47f4-a39c-f8258d939922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156076</td>\n",
       "      <td>8546</td>\n",
       "      <td>Kidman is really the only thing that 's worth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156154</td>\n",
       "      <td>8547</td>\n",
       "      <td>Once you get into its rhythm ... the movie bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156178</td>\n",
       "      <td>8548</td>\n",
       "      <td>I kept wishing I was watching a documentary ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156219</td>\n",
       "      <td>8549</td>\n",
       "      <td>Kinnear does n't aim for our sympathy , but ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156076        8546  Kidman is really the only thing that 's worth ...\n",
       "2    156154        8547  Once you get into its rhythm ... the movie bec...\n",
       "3    156178        8548  I kept wishing I was watching a documentary ab...\n",
       "4    156219        8549  Kinnear does n't aim for our sympathy , but ra..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf = cleanInitialTestFrame(initialTestFrame)\n",
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79094ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerAllPhrases(df):\n",
    "    phrases_list = list(df['Phrase'])\n",
    "\n",
    "    for i in range(len(phrases_list)):\n",
    "        phrases_list[i] = phrases_list[i].lower()\n",
    "    count = 0;\n",
    "    for index, row in df.iterrows():\n",
    "        df.at[index,'Phrase'] = phrases_list[count]\n",
    "        count += 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5413fd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>this quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>even fans of ismail merchant 's work , i suspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>a positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  a series of escapades demonstrating the adage ...   \n",
       "1        64           2  this quiet , introspective and entertaining in...   \n",
       "2        82           3  even fans of ismail merchant 's work , i suspe...   \n",
       "3       117           4  a positively thrilling combination of ethnogra...   \n",
       "4       157           5  aggressive self-glorification and a manipulati...   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          4  \n",
       "2          1  \n",
       "3          3  \n",
       "4          1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowerAllPhrases(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68043b85-a448-4631-88bf-4282d9f5f5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>an intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156076</td>\n",
       "      <td>8546</td>\n",
       "      <td>kidman is really the only thing that 's worth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156154</td>\n",
       "      <td>8547</td>\n",
       "      <td>once you get into its rhythm ... the movie bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156178</td>\n",
       "      <td>8548</td>\n",
       "      <td>i kept wishing i was watching a documentary ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156219</td>\n",
       "      <td>8549</td>\n",
       "      <td>kinnear does n't aim for our sympathy , but ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  an intermittently pleasing but mostly routine ...\n",
       "1    156076        8546  kidman is really the only thing that 's worth ...\n",
       "2    156154        8547  once you get into its rhythm ... the movie bec...\n",
       "3    156178        8548  i kept wishing i was watching a documentary ab...\n",
       "4    156219        8549  kinnear does n't aim for our sympathy , but ra..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowerAllPhrases(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15eb27c8-3e41-411a-adb8-adfbfedbf29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-ascii characters using str.replace()\n",
    "def asciiClean(df):\n",
    "    # iterate row by row\n",
    "    for index, row in df.iterrows():\n",
    "        old_str = row['Phrase']\n",
    "        new_str = (old_str.encode('ascii','ignore')).decode()\n",
    "        df.at[index, 'Phrase'] = new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3544c935-4b22-4694-bcfa-1cea5e307ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>this quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>even fans of ismail merchant 's work , i suspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>a positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  a series of escapades demonstrating the adage ...   \n",
       "1        64           2  this quiet , introspective and entertaining in...   \n",
       "2        82           3  even fans of ismail merchant 's work , i suspe...   \n",
       "3       117           4  a positively thrilling combination of ethnogra...   \n",
       "4       157           5  aggressive self-glorification and a manipulati...   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          4  \n",
       "2          1  \n",
       "3          3  \n",
       "4          1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asciiClean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdf94c8-b5f9-443b-87e5-9174e22ecfa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>an intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156076</td>\n",
       "      <td>8546</td>\n",
       "      <td>kidman is really the only thing that 's worth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156154</td>\n",
       "      <td>8547</td>\n",
       "      <td>once you get into its rhythm ... the movie bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156178</td>\n",
       "      <td>8548</td>\n",
       "      <td>i kept wishing i was watching a documentary ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156219</td>\n",
       "      <td>8549</td>\n",
       "      <td>kinnear does n't aim for our sympathy , but ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  an intermittently pleasing but mostly routine ...\n",
       "1    156076        8546  kidman is really the only thing that 's worth ...\n",
       "2    156154        8547  once you get into its rhythm ... the movie bec...\n",
       "3    156178        8548  i kept wishing i was watching a documentary ab...\n",
       "4    156219        8549  kinnear does n't aim for our sympathy , but ra..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asciiClean(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d591f9e-4d34-4e4e-ad0a-86b5fa857531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def removeSpaces(df):\n",
    "    for index, row in df.iterrows():\n",
    "        # df['Phrase'] = df['Phrase'].replace([row['Phrase']], re.sub(r'\\s+\\'', \"'\", row['Phrase']))\n",
    "        df.at[index,'Phrase'] = re.sub(r'\\s+\\'', \"'\", row['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60e9877-ff45-4f2c-9f27-7b7be16d7ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeSpaces(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76807d3d-1f94-44bd-8ddc-27107794c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeSpaces(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f1351-a2cf-47e2-aa2c-6b317654e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "contractions.add('n\\'t', 'not')\n",
    "def expandContractions(df):\n",
    "    for index, row in df.iterrows():\n",
    "        phrase = []\n",
    "        for i in row['Phrase'].split():\n",
    "            phrase.append(contractions.fix(i))\n",
    "        string_version = ' '.join(phrase)\n",
    "        df.at[index, 'Phrase'] = string_version            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8090cd-7829-4229-8fa5-3acebc9ab3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "expandContractions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea3aa78-2ba4-41a1-a54e-bbed95550c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "expandContractions(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1953719b-cfcf-4305-a85e-87229e86971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def removePunctuation(df):\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    for index,row in df.iterrows():\n",
    "        phrase = []\n",
    "        for i in row['Phrase'].split():\n",
    "            phrase.append(regex.sub('', i))\n",
    "        string_version = ' '.join(phrase)\n",
    "        df.at[index, 'Phrase'] = string_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efef7239-e180-4929-8dff-fb10b351f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "removePunctuation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d8266f-14b1-489e-baa8-c113fe93103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "removePunctuation(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ec2e70-f456-4161-9f02-4365f68f4e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/muchlogic/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/muchlogic/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e666e402-ba3c-4df3-8a7f-1a0ab7cf14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(df):\n",
    "    \n",
    "    phrases_list = list(df['Phrase'])\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    for i in range(len(phrases_list)):\n",
    "        word_tokens = word_tokenize(phrases_list[i])\n",
    "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "        filtered_sentence = []\n",
    "        for w in word_tokens:\n",
    "            if w not in stop_words:\n",
    "                filtered_sentence.append(w)\n",
    "        phrases_list[i] = filtered_sentence\n",
    "    \n",
    "    for i in range(len(phrases_list)):\n",
    "        phrases_list[i] = TreebankWordDetokenizer().detokenize(phrases_list[i])\n",
    "    \n",
    "    count = 0\n",
    "    for index, row in df.iterrows():\n",
    "        # df['Phrase'] = df['Phrase'].replace([row['Phrase']], phrases_list[count])\n",
    "        df.at[index, 'Phrase'] = phrases_list[count]\n",
    "        count += 1\n",
    "\n",
    "    return df      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1abbf5a-b4b1-4ee3-b756-3ebd36ccc3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>series escapades demonstrating adage good goos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>quiet introspective entertaining independent w...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>even fans ismail merchants work suspect would ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>positively thrilling combination ethnography i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>aggressive selfglorification manipulative whit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>167</td>\n",
       "      <td>6</td>\n",
       "      <td>comedydrama nearly epic proportions rooted sin...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>199</td>\n",
       "      <td>7</td>\n",
       "      <td>narratively trouble every day plodding mess</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>214</td>\n",
       "      <td>8</td>\n",
       "      <td>importance earnest thick wit plays like readin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>248</td>\n",
       "      <td>9</td>\n",
       "      <td>leave much</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>260</td>\n",
       "      <td>10</td>\n",
       "      <td>could hate reason</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  series escapades demonstrating adage good goos...   \n",
       "1        64           2  quiet introspective entertaining independent w...   \n",
       "2        82           3  even fans ismail merchants work suspect would ...   \n",
       "3       117           4  positively thrilling combination ethnography i...   \n",
       "4       157           5  aggressive selfglorification manipulative whit...   \n",
       "5       167           6  comedydrama nearly epic proportions rooted sin...   \n",
       "6       199           7        narratively trouble every day plodding mess   \n",
       "7       214           8  importance earnest thick wit plays like readin...   \n",
       "8       248           9                                         leave much   \n",
       "9       260          10                                  could hate reason   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          4  \n",
       "2          1  \n",
       "3          3  \n",
       "4          1  \n",
       "5          4  \n",
       "6          1  \n",
       "7          3  \n",
       "8          1  \n",
       "9          1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = removeStopWords(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db63992-bd8e-4a73-8bdb-d8d7689e6bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156076</td>\n",
       "      <td>8546</td>\n",
       "      <td>kidman really thing worth watching birthday gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156154</td>\n",
       "      <td>8547</td>\n",
       "      <td>get rhythm movie becomes heady experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156178</td>\n",
       "      <td>8548</td>\n",
       "      <td>kept wishing watching documentary wartime nava...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156219</td>\n",
       "      <td>8549</td>\n",
       "      <td>kinnear aim sympathy rather delivers performan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156250</td>\n",
       "      <td>8550</td>\n",
       "      <td>ends well sort frenzied comic moments never click</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>156272</td>\n",
       "      <td>8551</td>\n",
       "      <td>hoot half great way american people see candid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>156324</td>\n",
       "      <td>8552</td>\n",
       "      <td>weight piece unerring professionalism chilly p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>156362</td>\n",
       "      <td>8553</td>\n",
       "      <td>film contains good jokes good scenes barely mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156405</td>\n",
       "      <td>8554</td>\n",
       "      <td>offbeat sometimes gross surprisingly appealing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545      intermittently pleasing mostly routine effort\n",
       "1    156076        8546  kidman really thing worth watching birthday gi...\n",
       "2    156154        8547          get rhythm movie becomes heady experience\n",
       "3    156178        8548  kept wishing watching documentary wartime nava...\n",
       "4    156219        8549  kinnear aim sympathy rather delivers performan...\n",
       "5    156250        8550  ends well sort frenzied comic moments never click\n",
       "6    156272        8551  hoot half great way american people see candid...\n",
       "7    156324        8552  weight piece unerring professionalism chilly p...\n",
       "8    156362        8553  film contains good jokes good scenes barely mo...\n",
       "9    156405        8554  offbeat sometimes gross surprisingly appealing..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf = removeStopWords(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3775faa-eb0c-4adb-8f67-07138761ee81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/muchlogic/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/muchlogic/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/muchlogic/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef2484b-5731-4c28-9d45-a288220fc236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize     \n",
    "def tag_words(df):\n",
    "    allPhrases = list(df['Phrase'])\n",
    "    for index,row in df.iterrows():\n",
    "        tokenized = word_tokenize(allPhrases[index])\n",
    "        tagged = nltk.pos_tag(tokenized)\n",
    "        df.at[index, 'Phrase'] = tagged\n",
    "\n",
    "def determine_root(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemmatize_phrases(df):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    allPhrases = list(df['Phrase'])\n",
    "    for index,row in df.iterrows():\n",
    "        final_sentence = []\n",
    "        final_tag = list(map(lambda x: (x[0], determine_root(x[1])), allPhrases[index]))\n",
    "        for word, tag in final_tag:\n",
    "            if tag is None:\n",
    "                final_sentence.append(word)\n",
    "            else:\n",
    "                final_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "        final_sentence = ' '.join(final_sentence)\n",
    "        df.at[index, 'Phrase'] = final_sentence             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1e301-5cf8-4136-aa77-ccf0923c17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_words(df)\n",
    "lemmatize_phrases(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63678295-da9b-43d4-ad4b-417fd07c8bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_words(testdf)\n",
    "lemmatize_phrases(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f855b0ee-0337-4313-8a73-7fdc82849d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>series escapades demonstrating adage good goos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>quiet introspective entertaining independent w...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>even fan ismail merchant work suspect would ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>positively thrill combination ethnography intr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>aggressive selfglorification manipulative whit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>167</td>\n",
       "      <td>6</td>\n",
       "      <td>comedydrama nearly epic proportion root sincer...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>199</td>\n",
       "      <td>7</td>\n",
       "      <td>narratively trouble every day plod mess</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>214</td>\n",
       "      <td>8</td>\n",
       "      <td>importance earnest thick wit play like read ba...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>248</td>\n",
       "      <td>9</td>\n",
       "      <td>leave much</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>260</td>\n",
       "      <td>10</td>\n",
       "      <td>could hate reason</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  series escapades demonstrating adage good goos...   \n",
       "1        64           2  quiet introspective entertaining independent w...   \n",
       "2        82           3  even fan ismail merchant work suspect would ha...   \n",
       "3       117           4  positively thrill combination ethnography intr...   \n",
       "4       157           5  aggressive selfglorification manipulative whit...   \n",
       "5       167           6  comedydrama nearly epic proportion root sincer...   \n",
       "6       199           7            narratively trouble every day plod mess   \n",
       "7       214           8  importance earnest thick wit play like read ba...   \n",
       "8       248           9                                         leave much   \n",
       "9       260          10                                  could hate reason   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          4  \n",
       "2          1  \n",
       "3          3  \n",
       "4          1  \n",
       "5          4  \n",
       "6          1  \n",
       "7          3  \n",
       "8          1  \n",
       "9          1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f042b-80fc-4ec0-833a-ee7978f4d3aa",
   "metadata": {},
   "source": [
    "# Convert our phrases to a bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfebf1c4-fa4b-4d60-b004-9ee6d148b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectDf = df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc56db-f1ca-4146-9cc9-8368aed6a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleWord(wordDict, word, index):\n",
    "    # Get the list corresponding to the word\n",
    "    cList = wordDict[word]\n",
    "    cLen = len(cList)\n",
    "    # Get the length of how many zeroes to make\n",
    "    # last space is for current word\n",
    "    zeroLen = index - cLen + 1\n",
    "    zeros = [0] * zeroLen\n",
    "    # Add zeros to the list\n",
    "    cList += zeros\n",
    "    cList[-1] += 1\n",
    "    # Set dictionary to list\n",
    "    wordDict[word] = cList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b672f0-494f-4cd5-bacb-175d9ed152c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a vector of words\n",
    "def createWordVector(df):\n",
    "    # Creates a dictionary of words\n",
    "    wordDict = {}\n",
    "    # Create a dictionary of lists for word frequencies in each phrase\n",
    "    for index, row in df.iterrows():\n",
    "        sentence = row['Phrase']\n",
    "        for word in sentence.split():\n",
    "            if word in wordDict:\n",
    "                handleWord(wordDict, word, index)\n",
    "            else:\n",
    "                wordDict[word] = []\n",
    "                handleWord(wordDict, word, index)\n",
    "    \n",
    "    \n",
    "    # Get the phrase count\n",
    "    dfLen = len(df['Phrase'])\n",
    "    cMax = 0\n",
    "    cMin = 100000\n",
    "    # Fill the word frequencies to the length of the dataframe\n",
    "    for key in wordDict:\n",
    "        cList = wordDict[key]\n",
    "        cLen = len(cList)\n",
    "        # Get the amount of zeros to fill\n",
    "        zeroLen = dfLen - cLen\n",
    "        zeros = [0] * zeroLen\n",
    "        cList += zeros\n",
    "        wordDict[key] = cList\n",
    "    \n",
    "    # Add each word to the dataFrame\n",
    "    df2 = pd.DataFrame.from_dict(wordDict)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c160acdd-5b04-425e-be07-56b540cbff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "subVectDf = createWordVector(vectDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf27a684-54c0-4e0b-a171-8878c3aa150e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>escapades</th>\n",
       "      <th>demonstrating</th>\n",
       "      <th>adage</th>\n",
       "      <th>good</th>\n",
       "      <th>goose</th>\n",
       "      <th>also</th>\n",
       "      <th>gander</th>\n",
       "      <th>occasionally</th>\n",
       "      <th>amuse</th>\n",
       "      <th>...</th>\n",
       "      <th>smallbudget</th>\n",
       "      <th>underworld</th>\n",
       "      <th>ganginfested</th>\n",
       "      <th>eastvs</th>\n",
       "      <th>servicable</th>\n",
       "      <th>goldie</th>\n",
       "      <th>laughingly</th>\n",
       "      <th>herrmann</th>\n",
       "      <th>avuncular</th>\n",
       "      <th>chortle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   series  escapades  demonstrating  adage  good  goose  also  gander  \\\n",
       "0       1          1              1      1     2      1     1       1   \n",
       "1       0          0              0      0     0      0     0       0   \n",
       "2       0          0              0      0     0      0     0       0   \n",
       "3       0          0              0      0     0      0     0       0   \n",
       "4       0          0              0      0     0      0     0       0   \n",
       "\n",
       "   occasionally  amuse  ...  smallbudget  underworld  ganginfested  eastvs  \\\n",
       "0             1      1  ...            0           0             0       0   \n",
       "1             0      0  ...            0           0             0       0   \n",
       "2             0      0  ...            0           0             0       0   \n",
       "3             0      0  ...            0           0             0       0   \n",
       "4             0      0  ...            0           0             0       0   \n",
       "\n",
       "   servicable  goldie  laughingly  herrmann  avuncular  chortle  \n",
       "0           0       0           0         0          0        0  \n",
       "1           0       0           0         0          0        0  \n",
       "2           0       0           0         0          0        0  \n",
       "3           0       0           0         0          0        0  \n",
       "4           0       0           0         0          0        0  \n",
       "\n",
       "[5 rows x 14112 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subVectDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba059d-41b6-4728-98a1-aea239b7b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectDf = pd.concat([vectDf, subVectDf], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd38f7-cc1e-4903-a8b6-353c847e0627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>series</th>\n",
       "      <th>escapades</th>\n",
       "      <th>demonstrating</th>\n",
       "      <th>adage</th>\n",
       "      <th>good</th>\n",
       "      <th>goose</th>\n",
       "      <th>...</th>\n",
       "      <th>smallbudget</th>\n",
       "      <th>underworld</th>\n",
       "      <th>ganginfested</th>\n",
       "      <th>eastvs</th>\n",
       "      <th>servicable</th>\n",
       "      <th>goldie</th>\n",
       "      <th>laughingly</th>\n",
       "      <th>herrmann</th>\n",
       "      <th>avuncular</th>\n",
       "      <th>chortle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>series escapades demonstrating adage good goos...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>quiet introspective entertaining independent w...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>even fan ismail merchant work suspect would ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>positively thrill combination ethnography intr...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>aggressive selfglorification manipulative whit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  series escapades demonstrating adage good goos...   \n",
       "1        64           2  quiet introspective entertaining independent w...   \n",
       "2        82           3  even fan ismail merchant work suspect would ha...   \n",
       "3       117           4  positively thrill combination ethnography intr...   \n",
       "4       157           5  aggressive selfglorification manipulative whit...   \n",
       "\n",
       "   Sentiment  series  escapades  demonstrating  adage  good  goose  ...  \\\n",
       "0          1       1          1              1      1     2      1  ...   \n",
       "1          4       0          0              0      0     0      0  ...   \n",
       "2          1       0          0              0      0     0      0  ...   \n",
       "3          3       0          0              0      0     0      0  ...   \n",
       "4          1       0          0              0      0     0      0  ...   \n",
       "\n",
       "   smallbudget  underworld  ganginfested  eastvs  servicable  goldie  \\\n",
       "0            0           0             0       0           0       0   \n",
       "1            0           0             0       0           0       0   \n",
       "2            0           0             0       0           0       0   \n",
       "3            0           0             0       0           0       0   \n",
       "4            0           0             0       0           0       0   \n",
       "\n",
       "   laughingly  herrmann  avuncular  chortle  \n",
       "0           0         0          0        0  \n",
       "1           0         0          0        0  \n",
       "2           0         0          0        0  \n",
       "3           0         0          0        0  \n",
       "4           0         0          0        0  \n",
       "\n",
       "[5 rows x 14116 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556c1808-1675-4044-92e4-d4c167f1eca9",
   "metadata": {},
   "source": [
    "# Selene Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af0d713-b74e-44ab-90d1-5780bfe2843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class Selene(object):\n",
    "    \n",
    "    def __init__(self, df, testdf):\n",
    "        \n",
    "        self.df = df\n",
    "        self.testdf = testdf\n",
    "        self.wordsDict = {}\n",
    "        self.wordSentOcc = {}\n",
    "        self.wordSentVal = {}\n",
    "        self.results = pd.DataFrame\n",
    "    \n",
    "    def train(self, printer = False):\n",
    "        # Tokenizes phrases and finds frequency & sentiment\n",
    "        self.setUniqueWords()\n",
    "        self.setFrequencies()\n",
    "        self.findSentFrequency()\n",
    "        if printer:\n",
    "            counter = 0;\n",
    "            print(\"Words = [Frequency, 0 Freq, 1 Freq, 2 Freq, 3 Freq, 4 Freq]\")\n",
    "            for key, value in self.wordsDict.items():\n",
    "                print(\"Word #\", counter, \":\", key, \"-\", value)\n",
    "                counter += 1\n",
    "    \n",
    "    def test(self, weight = 0.4, minFreq = 3):\n",
    "        self.findWordSentVal()\n",
    "        results = self.getSentiment(weight, minFreq)\n",
    "        return results\n",
    "    \n",
    "    # Finds unique words in the list of phrases and puts into list\n",
    "    def setUniqueWords(self):\n",
    "        \n",
    "        phrases = list(self.df['Phrase'])\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            sentence = row['Phrase']\n",
    "            for w in word_tokenize(sentence): # word_tokens:\n",
    "                if w.isalpha():\n",
    "                    self.wordsDict[w] = [0,0,0,0,0,0]\n",
    "                    \n",
    "    def setFrequencies(self):\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            sentence = row['Phrase']\n",
    "            for word in sentence.split():\n",
    "                if word in self.wordsDict:\n",
    "                    self.wordsDict[word][0] += 1           \n",
    "    \n",
    "    # Finds frequencies of the sentiment per word\n",
    "    def findSentFrequency(self):\n",
    "                    \n",
    "        for index, row in df.iterrows():\n",
    "            sentiment = int(row['Sentiment'])\n",
    "            for word in row['Phrase'].split():\n",
    "                if word in self.wordsDict:\n",
    "                    try:\n",
    "                        self.wordsDict[word][sentiment + 1] += 1\n",
    "                    except:\n",
    "                        print(sentiment + 1)\n",
    "            \n",
    "    # Finds probabilities for a word's sentiment\n",
    "    def findProbabilities(self, key):\n",
    "        \n",
    "        prob0 = self.wordsDict[key][0 + 1] / self.wordsDict[key][0]\n",
    "        prob1 = self.wordsDict[key][1 + 1] / self.wordsDict[key][0]\n",
    "        prob2 = self.wordsDict[key][2 + 1] / self.wordsDict[key][0]\n",
    "        prob3 = self.wordsDict[key][3 + 1] / self.wordsDict[key][0]\n",
    "        prob4 = self.wordsDict[key][4 + 1] / self.wordsDict[key][0]\n",
    "        return prob0, prob1, prob2, prob3, prob4\n",
    "    \n",
    "    # Finds the average sentiment of a word\n",
    "    def findWordSentVal(self):\n",
    "        \n",
    "        for key, value in self.wordsDict.items():\n",
    "            sentVal = (((value[0 + 1] * 0) + (value[1 + 1] * 1) + (value[2 + 1] * 2)\n",
    "                    + (value[3 + 1] * 3) + (value[4 + 1] * 4)) / self.wordsDict[key][0])\n",
    "            prob0, prob1, prob2, prob3, prob4 = self.findProbabilities(key)\n",
    "            self.wordSentVal[key] = {'Avg Value': sentVal,'P0': prob0,\n",
    "                                     'P1': prob1, 'P2': prob2, \n",
    "                                     'P3': prob3, 'P4': prob4}\n",
    "            \n",
    "\n",
    "    \n",
    "    # Gets probability weights\n",
    "    def getWeight(self, word, weightPercent):\n",
    "        \n",
    "        mystery = random.random()\n",
    "        dip0 = self.wordSentVal[word]['P0']\n",
    "        dip1 = dip0 + self.wordSentVal[word]['P1']\n",
    "        dip2 = dip1 + self.wordSentVal[word]['P2']\n",
    "        dip3 = dip2 + self.wordSentVal[word]['P3']\n",
    "        dip4 = dip3 + self.wordSentVal[word]['P4']\n",
    "            \n",
    "        if (mystery >= 0 and mystery < dip0):\n",
    "            return -2 * weightPercent\n",
    "        elif (mystery >= dip0 and mystery < dip1):\n",
    "            return -1 * weightPercent\n",
    "        elif (mystery >= dip1 and mystery < dip2):\n",
    "            return 0\n",
    "        elif (mystery >= dip2 and mystery < dip3):\n",
    "            return 1 * weightPercent\n",
    "        elif (mystery >= dip3 and mystery <= dip4):\n",
    "            return 2 * weightPercent\n",
    "    \n",
    "    def mostOccurances(self, word):\n",
    "        \n",
    "        buffer = -1\n",
    "        maximum = []\n",
    "        for i in range(1,6):\n",
    "            if self.wordsDict[word][i] > buffer:\n",
    "                buffer = self.wordsDict[word][i]\n",
    "                maximum.clear()\n",
    "                maximum.append(i - 1)\n",
    "            if self.wordsDict[word][i] >= buffer:\n",
    "                maximum.append(i - 1)\n",
    "        \n",
    "        if len(maximum) == 1:\n",
    "            return maximum[0]\n",
    "        else:\n",
    "            return sum(maximum)/len(maximum)\n",
    "        \n",
    "    # Gets the sentiment of a phrase\n",
    "    def getSentiment(self, weightPercent = .4, minimumOccurances = 4):\n",
    "        \n",
    "        Sentiments = []\n",
    "        for index, row in self.testdf.iterrows():\n",
    "            \n",
    "            phraseVal = 0\n",
    "            counter = 0\n",
    "            \n",
    "            for word in row['Phrase'].split():\n",
    "                \n",
    "                if word in self.wordSentVal and self.wordsDict[word][0] >= minimumOccurances:\n",
    "                    weight = self.getWeight(word, weightPercent)\n",
    "                    phraseVal += self.wordSentVal[word]['Avg Value'] + weight\n",
    "                    counter += 1\n",
    "                    #if index == 3:\n",
    "                     #   print(word, self.wordsDict[word][0], self.wordSentVal[word]['Avg Value'], weight)\n",
    "                        \n",
    "                elif word in self.wordSentVal and self.wordsDict[word][0] < minimumOccurances:\n",
    "                    weight = self.getWeight(word, weightPercent)\n",
    "                    most = self.mostOccurances(word)\n",
    "                    phraseVal += random.uniform(most - .5, most + .5) + weight\n",
    "                    counter += 1\n",
    "                    #if index == 3:\n",
    "                     #   print(word, self.wordsDict[word][0], most, weight)\n",
    "                        \n",
    "                # Neutral sentiment for unknown word\n",
    "                #else:\n",
    "                 #   phraseVal += random.randint(0, 4)\n",
    "                  #  counter += 1\n",
    "                    \n",
    "            if counter > 0:\n",
    "                #len(row['Phrase'].split())\n",
    "                sentVal = phraseVal/counter\n",
    "                if (sentVal < 0):\n",
    "                    sentVal = 0\n",
    "                elif (sentVal > 4):\n",
    "                    sentVal = 4\n",
    "                Sentiments.append(sentVal)\n",
    "            else:\n",
    "                Sentiments.append(0)\n",
    "            #print(row['Phrase'], Sentiments[index])\n",
    "                        \n",
    "        # testdf['Sentiment'] = Sentiments\n",
    "        #for value in Sentiments:\n",
    "         #   print(value)\n",
    "        # print(Sentiments[1], Sentiments[5])\n",
    "        print(len(list(testdf['Phrase'])), len(Sentiments))\n",
    "        data = {'Phrase': list(testdf['Phrase']), 'Sentiment Predicted': Sentiments}\n",
    "        self.results = pd.DataFrame(data)\n",
    "        return self.results\n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c188e5-b06e-45c4-b591-aab0a1df1e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selene = Selene(df, testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e95b78-9ba8-4580-8b00-ccdf93064872",
   "metadata": {},
   "outputs": [],
   "source": [
    "selene.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2786de-3131-429f-97dd-24b740c23f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = selene.test(weight = .75, minFreq = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f4818-5f83-460d-9b5e-641ec3ebd43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent.to_csv('Predicted_Results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
